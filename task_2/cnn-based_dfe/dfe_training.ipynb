{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-23T10:18:11.196305Z","iopub.status.busy":"2023-11-23T10:18:11.195350Z","iopub.status.idle":"2023-11-23T10:18:11.237451Z","shell.execute_reply":"2023-11-23T10:18:11.236707Z","shell.execute_reply.started":"2023-11-23T10:18:11.196272Z"},"papermill":{"duration":8.87465,"end_time":"2023-10-11T09:27:16.758128","exception":false,"start_time":"2023-10-11T09:27:07.883478","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from matplotlib import pyplot as plt\n","from keras.models import Model\n","from tensorflow.image import ssim\n","import tensorflow_probability as tfp\n","import numpy as np\n","from IPython import display\n","import cv2\n","\n","import tensorflow as tf\n","import os\n","import pathlib\n","import time\n","import datetime\n","import glob\n","import gc\n","\n","DATASET_PATH = 'task_2/dataset/processed_hk_norm_unenhanced_aug_iris_dataset_64x240_png/'\n","\n","# The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\n","BATCH_SIZE = 4\n","\n","IMG_HEIGHT = 64\n","IMG_WIDTH = 240\n","# --------------------------------------------------------------------------------------------------------------- #\n","\n","# data disrtibution \n","\n","# 209 subjects \n","# 150 training   72%\n","# 30 validation  14%\n","# 29 testing     14%\n","\n","# split in train - validation - test\n","\n","training_files = glob.glob(DATASET_PATH + 'train/*.png')\n","test_files = glob.glob(DATASET_PATH + 'test/*.png')\n","test_files.sort()\n","trainingset_size = len(training_files)\n","\n","validation_files = []\n","new_test_files = []\n","len_file = len(test_files[1])\n","\n","i=0\n","for file in test_files:\n","    sub = test_files[i][len_file-11:len_file-8]\n","    if int(sub) <= 180 :\n","        validation_files.append(file)\n","    else :\n","        new_test_files.append(file)\n","    i = i+1\n","\n","\n","validationset_size = len(validation_files)\n","\n","test_files = new_test_files\n","testset_size = len(test_files)\n","\n","DATASET_PATH  = pathlib.Path(DATASET_PATH)\n","\n","# --------------------------------------------------------------------------------------------------------------- #\n","\n","# instead of epochs\n","EPOCHS = 150\n","\n","N_EPOCHS_EARLY_STOPPING = 40 \n","NSTEPS = trainingset_size * EPOCHS\n","\n","INPUT_CHANNELS = 1\n","OUTPUT_CHANNELS = 4\n","\n","# buffer size is equal to training set size\n","BUFFER_SIZE = trainingset_size\n","\n","# log directory \n","LOG_DIR = \"logs/\" + '_nsteps_' + str(NSTEPS) + '_batchsize_' + str(BATCH_SIZE)  + '/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:11.239340Z","iopub.status.busy":"2023-11-23T10:18:11.239074Z","iopub.status.idle":"2023-11-23T10:18:11.245410Z","shell.execute_reply":"2023-11-23T10:18:11.244531Z","shell.execute_reply.started":"2023-11-23T10:18:11.239317Z"},"papermill":{"duration":0.016547,"end_time":"2023-10-11T09:27:16.781820","exception":false,"start_time":"2023-10-11T09:27:16.765273","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load(image_file):\n","    # Read and decode an image file to a uint8 tensor\n","    image = tf.io.read_file(image_file)\n","    image = tf.io.decode_png(image)\n","        \n","    # Split each image tensor into two tensors:\n","    # - one with a real building facade image\n","    # - one with an architecture label image \n","    w = tf.shape(image)[1]\n","    w = w // 2\n","\n","    input_image = image[:, :w, :]\n","    real_image = image[:, w:, :]\n","\n","    # Convert both images to float32 tensors\n","    input_image = tf.cast(input_image, tf.float32)\n","    real_image = tf.cast(real_image, tf.float32)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:11.247065Z","iopub.status.busy":"2023-11-23T10:18:11.246692Z","iopub.status.idle":"2023-11-23T10:18:11.256605Z","shell.execute_reply":"2023-11-23T10:18:11.255883Z","shell.execute_reply.started":"2023-11-23T10:18:11.247035Z"},"trusted":true},"outputs":[],"source":["def resize(input_image, real_image, height, width):\n","    input_image = tf.image.resize(input_image, [height, width],\n","                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    real_image = tf.image.resize(real_image, [height, width],\n","                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    \n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:11.258799Z","iopub.status.busy":"2023-11-23T10:18:11.258498Z","iopub.status.idle":"2023-11-23T10:18:11.266542Z","shell.execute_reply":"2023-11-23T10:18:11.265784Z","shell.execute_reply.started":"2023-11-23T10:18:11.258774Z"},"trusted":true},"outputs":[],"source":["def normalize(input_image, real_image):\n","    input_image = (input_image / 127.5) - 1\n","    real_image = (real_image / 127.5) - 1\n","\n","    return input_image, real_image\n","\n","def denormalize(input_image, real_image): # to [0, 255]\n","    input_image = (input_image + 1) * 127.5\n","    real_image = (real_image + 1) * 127.5\n","\n","    return real_image\n","\n","def normalize2(input_image, real_image) :\n","    \n","    mean = tf.math.reduce_mean(input_image)\n","    std = tf.math.reduce_std(input_image)\n","    input_image = tf.clip_by_value((input_image - mean) / std, clip_value_min=-1.0, clip_value_max=1.0)\n","\n","    mean = tf.math.reduce_mean(real_image)\n","    std = tf.math.reduce_std(real_image)\n","    real_image = tf.clip_by_value((real_image - mean) / std, clip_value_min=-1.0, clip_value_max=1.0)\n","    \n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:11.457688Z","iopub.status.busy":"2023-11-23T10:18:11.457430Z","iopub.status.idle":"2023-11-23T10:18:11.487985Z","shell.execute_reply":"2023-11-23T10:18:11.487110Z","shell.execute_reply.started":"2023-11-23T10:18:11.457666Z"},"trusted":true},"outputs":[],"source":["# daugman feature extraction algorithm\n","\n","def tf_ProcessSingleChannel(channel):\n","    h = tf.histogram_fixed_width(channel, value_range=(0, 255), nbins=256)\n","\n","    h = tf.cast(h, tf.float32)\n","    pixel_values = tf.range(256, dtype=tf.float32)\n","    \n","    weighted_sum = tf.reduce_sum(pixel_values * h)\n","    total_pixels = tf.reduce_sum(h)\n","    mean_val = weighted_sum / total_pixels\n","\n","    # Compute variance and standard deviation\n","    variance = tf.reduce_sum(((pixel_values - mean_val) ** 2) * h) / total_pixels\n","    std_dev = tf.sqrt(variance)\n","\n","    # Compute Gaussian values\n","    gaussian_vals = (1 / (std_dev * tf.sqrt(2 * np.pi))) * tf.exp(-0.5 * ((pixel_values - mean_val) / std_dev) ** 2)\n","\n","    # Set threshold\n","    threshold = tf.reduce_max(gaussian_vals) * 0.1  # For example, 10% of the maximum\n","\n","    # Find values to eliminate\n","    to_eliminate = gaussian_vals < threshold\n","\n","    ProcessedChannel = tf.identity(channel)  # Create a copy\n","\n","    # Replace values below the threshold\n","    for i in range(len(to_eliminate)):\n","        if to_eliminate[i]:\n","            ProcessedChannel = tf.where(channel == i, mean_val + std_dev, ProcessedChannel)\n","\n","    return ProcessedChannel\n","\n","def tf_GaussHistCut(image):\n","    channels = 1\n","    if len(image.shape) > 2:\n","        _, _, channels = image.shape\n","\n","    if channels == 3:  # RGB image\n","        CorrectedImage = tf.zeros_like(image, dtype=tf.uint8)\n","\n","        for ch in range(channels):\n","            CorrectedImage[:, :, ch] = tf_ProcessSingleChannel(image[:, :, ch])\n","    \n","    else:  # Grayscale image\n","        CorrectedImage = tf_ProcessSingleChannel(image)\n","\n","    return CorrectedImage\n","\n","def tf_rescale(data):\n","    data_min = tf.reduce_min(data)\n","    data_max = tf.reduce_max(data)\n","    return (data - data_min) / (data_max - data_min)\n","\n","def tf_mad_normalize(channel):\n","    mad = tfp.stats.percentile(tf.abs(channel - tfp.stats.percentile(channel, 50)), 50)\n","    is_zero_mad = tf.equal(mad, 0)\n","    channel = tf.where(is_zero_mad, tf.zeros_like(channel), (channel - tfp.stats.percentile(channel, 50)) / mad)\n","    return tf_rescale(channel)\n","\n","def tf_daugman_normalization(image):\n","\n","    AR, AG, AB = tf.split(image, num_or_size_splits=3, axis=-1)\n","\n","    # Apply GaussHistCut\n","    AR = tf_GaussHistCut(AR)\n","    #AG = tf_GaussHistCut(AG)\n","    #AB = tf_GaussHistCut(AB)\n","\n","    AR = tf_mad_normalize(AR)\n","    #AG = tf_mad_normalize(AG)\n","    #AB = tf_mad_normalize(AB)\n","\n","    # Replace NaN and Inf values with 0\n","    AR = tf.where(tf.math.is_nan(AR) | tf.math.is_inf(AR), tf.zeros_like(AR), AR)\n","    #AG = tf.where(tf.math.is_nan(AG) | tf.math.is_inf(AG), tf.zeros_like(AG), AG)\n","    #AB = tf.where(tf.math.is_nan(AB) | tf.math.is_inf(AB), tf.zeros_like(AB), AB)\n","\n","    # Create the normalized image\n","    #norm_image = tf.concat([AR, AG, AB], axis=-1)\n","\n","    return AR #return norm_image\n","    \n","def tf_gaborconvolve(im, nscale, minWaveLength, mult, sigmaOnf):\n","    rows = IMG_HEIGHT #im.shape[0]\n","    cols = IMG_WIDTH #im.shape[1]\n","    \n","    filtersum = tf.zeros(cols, dtype=tf.float32)\n","    EO = [None] * nscale\n","    \n","    ndata = cols\n","\n","    logGabor = tf.zeros(ndata, dtype=tf.float32)\n","    result = tf.zeros([rows, ndata], dtype=tf.complex128)\n","    \n","    radius = tf.range(0, ndata // 2 + 1, dtype=tf.float64) / (ndata // 2) / 2  # Frequency values 0 - 0.5\n","    zerovalue = tf.cast(tf.constant([1.0]), dtype=tf.float64)\n","    radius = tf.tensor_scatter_nd_update(radius, tf.constant([[0]]), zerovalue)\n","    \n","    wavelength = minWaveLength  # Initialize filter wavelength\n","    \n","    for s in range(nscale):\n","        # Construct the filter - first calculate the radial filter component\n","        fo = 1.0 / wavelength  # Centre frequency of filter\n","        # corresponding to fo\n","        \n","        sum = tf.exp( tf.cast( - tf.pow((tf.math.log(radius/fo)), 2), dtype=tf.float32) / (2 * tf.pow(tf.math.log(sigmaOnf), 2)))\n","\n","\n","        indexes = tf.expand_dims(tf.range(0, sum.shape[0]), axis=1)\n","\n","        logGabor = tf.tensor_scatter_nd_update(logGabor, indexes, sum)\n","        logGabor = tf.tensor_scatter_nd_update(logGabor, tf.constant([[0]]), tf.constant([0.0]))\n","        \n","        filter = logGabor\n","        filtersum = filtersum + filter\n","        \n","        for r in range(rows):\n","            signal = im[r, 0:ndata]\n","            imagefft = tf.signal.fft(tf.cast(signal, dtype=tf.complex128))\n","            filter = tf.cast(filter, dtype=tf.complex128)\n","            result = tf.tensor_scatter_nd_add(result, [tf.constant([r])], [tf.signal.ifft(imagefft * filter)])\n","        \n","        EO[s] = result\n","        wavelength *= mult  # Finally calculate the wavelength of the next filter\n","    \n","    filtersum = tf.signal.fftshift(filtersum)\n","    \n","    return EO, filtersum\n","\n","def tf_encode(polar_array, nscales, minWaveLength, mult, sigmaOnf):\n","    # Convoluzione della regione normalizzata con filtri di Gabor\n","    E0, _ = tf_gaborconvolve(polar_array, nscales, minWaveLength, mult, sigmaOnf)\n","    \n","    H = tf.zeros(E0[0].shape)\n","    for k in range(1, nscales + 1):\n","        E1 = E0[k - 1]\n","\n","        cond_0 = tf.math.logical_and(tf.math.real(E1) <= 0, tf.math.imag(E1) <= 0)\n","        cond_1 = tf.math.logical_and(tf.math.real(E1) <= 0, tf.math.imag(E1) > 0)\n","        cond_2 = tf.math.logical_and(tf.math.real(E1) > 0, tf.math.imag(E1) <= 0)\n","        cond_3 = tf.math.logical_and(tf.math.real(E1) > 0, tf.math.imag(E1) > 0)\n","\n","        H=tf.where(cond_0,0.0,H)\n","        H=tf.where(cond_1,1.0,H)\n","        H=tf.where(cond_2,2.0,H)\n","        H=tf.where(cond_3,3.0,H)\n","\n","    return H\n","\n","def tf_GaborBitStreamSTACKED(AR): #polarImage):\n","\n","    #AR, AG, AB = tf.split(polarImage, num_or_size_splits=3, axis=-1)\n","\n","    nscales = 1\n","    minWaveLength = 24\n","    mult = 1\n","    sigmaOnf = 0.5\n","\n","    TR = tf_encode(tf.squeeze(AR), nscales, minWaveLength, mult, sigmaOnf)\n","    #TG = tf_encode(tf.squeeze(AG), nscales, minWaveLength, mult, sigmaOnf)\n","    #TB = tf_encode(tf.squeeze(AB), nscales, minWaveLength, mult, sigmaOnf)\n","\n","    TR = tf.cast(TR, dtype=tf.uint8)\n","\n","    return tf.expand_dims(TR, axis=2) #return tf.concat([tf.expand_dims(TR, axis=2) , tf.expand_dims(TG, axis=2), tf.expand_dims(TB, axis=2)], axis=-1)\n","\n","def tf_daugman_feature_extractor(inp):\n","    return tf_GaborBitStreamSTACKED(inp)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:11.489302Z","iopub.status.busy":"2023-11-23T10:18:11.489060Z","iopub.status.idle":"2023-11-23T10:18:11.899677Z","shell.execute_reply":"2023-11-23T10:18:11.898722Z","shell.execute_reply.started":"2023-11-23T10:18:11.489282Z"},"trusted":true},"outputs":[],"source":["# printing input image - feature image\n","\n","inp, tar = load(training_files[0])\n","\n","display_list = [(inp/255.0), (tar/255.0)]\n","title = ['Input Image', 'Target Image']\n","plt.figure(figsize=(15, 15))\n","\n","for i in range(2):\n","    plt.subplot(1, 2, i+1)\n","    plt.title(title[i])\n","    plt.imshow(display_list[i])\n","    #plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:11.901266Z","iopub.status.busy":"2023-11-23T10:18:11.900971Z","iopub.status.idle":"2023-11-23T10:18:12.560066Z","shell.execute_reply":"2023-11-23T10:18:12.559145Z","shell.execute_reply.started":"2023-11-23T10:18:11.901240Z"},"trusted":true},"outputs":[],"source":["inp, tar = load(training_files[0])\n","norm_inp, norm_tar = normalize2(inp, tar)\n","\n","IR,IG,IB = tf.split(norm_inp, num_or_size_splits=3, axis=-1)\n","TR,TG,TB = tf.split(norm_tar, num_or_size_splits=3, axis=-1)\n","\n","fi_real_image = tf_daugman_feature_extractor(TR)\n","\n","\n","display_list = [(norm_tar*0.5+0.5), fi_real_image]\n","title = ['input_image', 'target_feature_image']\n","plt.figure(figsize=(15, 15))\n","\n","for i in range(2):\n","    plt.subplot(1, 2, i+1)\n","    plt.title(title[i])\n","    plt.imshow(display_list[i])\n","    #plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:12.925671Z","iopub.status.busy":"2023-11-23T10:18:12.925367Z","iopub.status.idle":"2023-11-23T10:18:12.931687Z","shell.execute_reply":"2023-11-23T10:18:12.930643Z","shell.execute_reply.started":"2023-11-23T10:18:12.925645Z"},"papermill":{"duration":0.014732,"end_time":"2023-10-11T09:27:20.547759","exception":false,"start_time":"2023-10-11T09:27:20.533027","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_train(image_file):\n","    \n","    _, real_image = load(image_file)\n","    _, norm_real_image = normalize2(_, real_image)\n","\n","    norm_R, _, _ = tf.split(norm_real_image, num_or_size_splits=3, axis=-1)\n","\n","    fi_real_image = tf_daugman_feature_extractor(norm_R)\n","\n","    return norm_R, fi_real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:12.933150Z","iopub.status.busy":"2023-11-23T10:18:12.932848Z","iopub.status.idle":"2023-11-23T10:18:12.942148Z","shell.execute_reply":"2023-11-23T10:18:12.941110Z","shell.execute_reply.started":"2023-11-23T10:18:12.933128Z"},"papermill":{"duration":0.01435,"end_time":"2023-10-11T09:27:20.569005","exception":false,"start_time":"2023-10-11T09:27:20.554655","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_validation(image_file):\n","    \n","    _, real_image = load(image_file)\n","    _, norm_real_image = normalize2(_, real_image)\n","    \n","    norm_R, _, _ = tf.split(norm_real_image, num_or_size_splits=3, axis=-1)\n","\n","    fi_real_image = tf_daugman_feature_extractor(norm_R)\n","\n","    return norm_R, fi_real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:12.943526Z","iopub.status.busy":"2023-11-23T10:18:12.943249Z","iopub.status.idle":"2023-11-23T10:18:12.954559Z","shell.execute_reply":"2023-11-23T10:18:12.953783Z","shell.execute_reply.started":"2023-11-23T10:18:12.943504Z"},"papermill":{"duration":0.014275,"end_time":"2023-10-11T09:27:20.590115","exception":false,"start_time":"2023-10-11T09:27:20.575840","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_test(image_file):\n","    \n","    _, real_image = load(image_file)\n","    _, norm_real_image = normalize2(_, real_image)\n","    \n","    norm_R, _, _ = tf.split(norm_real_image, num_or_size_splits=3, axis=-1)\n","\n","    fi_real_image = tf_daugman_feature_extractor(norm_R)\n","\n","    return norm_R, fi_real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:12.955946Z","iopub.status.busy":"2023-11-23T10:18:12.955473Z","iopub.status.idle":"2023-11-23T10:18:15.135349Z","shell.execute_reply":"2023-11-23T10:18:15.134374Z","shell.execute_reply.started":"2023-11-23T10:18:12.955922Z"},"papermill":{"duration":0.869299,"end_time":"2023-10-11T09:27:21.466169","exception":false,"start_time":"2023-10-11T09:27:20.596870","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_dataset = tf.data.Dataset.list_files(str(DATASET_PATH / 'train/*.png'))\n","train_dataset = train_dataset.map(load_image_train,\n","                                  num_parallel_calls=tf.data.AUTOTUNE)\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n","train_dataset = train_dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:15.136940Z","iopub.status.busy":"2023-11-23T10:18:15.136584Z","iopub.status.idle":"2023-11-23T10:18:15.705644Z","shell.execute_reply":"2023-11-23T10:18:15.704854Z","shell.execute_reply.started":"2023-11-23T10:18:15.136908Z"},"papermill":{"duration":0.08507,"end_time":"2023-10-11T09:27:21.558480","exception":false,"start_time":"2023-10-11T09:27:21.473410","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["validation_dataset = tf.data.Dataset.from_tensor_slices(validation_files)\n","validation_dataset = validation_dataset.map(load_image_validation)\n","validation_dataset = validation_dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:15.707255Z","iopub.status.busy":"2023-11-23T10:18:15.706893Z","iopub.status.idle":"2023-11-23T10:18:16.259436Z","shell.execute_reply":"2023-11-23T10:18:16.258667Z","shell.execute_reply.started":"2023-11-23T10:18:15.707222Z"},"papermill":{"duration":0.073422,"end_time":"2023-10-11T09:27:21.639212","exception":false,"start_time":"2023-10-11T09:27:21.565790","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["test_dataset = tf.data.Dataset.from_tensor_slices(test_files)\n","test_dataset = test_dataset.map(load_image_test,\n","                                    num_parallel_calls=tf.data.AUTOTUNE)\n","test_dataset = test_dataset.batch(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.267566Z","iopub.status.busy":"2023-11-23T10:18:16.266799Z","iopub.status.idle":"2023-11-23T10:18:16.276432Z","shell.execute_reply":"2023-11-23T10:18:16.275507Z","shell.execute_reply.started":"2023-11-23T10:18:16.267534Z"},"papermill":{"duration":0.017581,"end_time":"2023-10-11T09:27:43.912245","exception":false,"start_time":"2023-10-11T09:27:43.894664","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def downsample(filters, size, apply_batchnorm=True):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    \n","    result = tf.keras.Sequential()\n","    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n","\n","    if apply_batchnorm:\n","        result.add(tf.keras.layers.BatchNormalization())\n","\n","    result.add(tf.keras.layers.LeakyReLU())\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.287095Z","iopub.status.busy":"2023-11-23T10:18:16.286807Z","iopub.status.idle":"2023-11-23T10:18:16.294093Z","shell.execute_reply":"2023-11-23T10:18:16.293271Z","shell.execute_reply.started":"2023-11-23T10:18:16.287073Z"},"papermill":{"duration":0.016394,"end_time":"2023-10-11T09:27:43.959065","exception":false,"start_time":"2023-10-11T09:27:43.942671","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def upsample(filters, size, apply_dropout=False):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","\n","    result = tf.keras.Sequential()\n","    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n","                                    padding='same',\n","                                    kernel_initializer=initializer,\n","                                    use_bias=False))\n","\n","    result.add(tf.keras.layers.BatchNormalization())\n","\n","    if apply_dropout:\n","        result.add(tf.keras.layers.Dropout(0.5))\n","\n","    result.add(tf.keras.layers.ReLU())\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.303847Z","iopub.status.busy":"2023-11-23T10:18:16.303548Z","iopub.status.idle":"2023-11-23T10:18:16.313404Z","shell.execute_reply":"2023-11-23T10:18:16.312505Z","shell.execute_reply.started":"2023-11-23T10:18:16.303824Z"},"papermill":{"duration":0.017731,"end_time":"2023-10-11T09:27:44.006635","exception":false,"start_time":"2023-10-11T09:27:43.988904","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def Generator():\n","    inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS])\n","\n","    down_stack = [\n","        downsample(64, 4, apply_batchnorm=False), \n","        downsample(128, 4),  \n","        downsample(256, 4), \n","        downsample(512, 4),  \n","      ]\n","\n","    up_stack = [\n","        upsample(256, 4, apply_dropout=True), \n","        upsample(128, 4),  \n","        upsample(64, 4),  \n","    ]\n","\n","\n","\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n","                                         strides=2,\n","                                         padding='same',\n","                                         kernel_initializer=initializer,\n","                                         activation='softmax') \n","\n","\n","    # --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- #\n","    x = inputs\n","\n","    # Downsampling through the model\n","    skips = []\n","    for down in down_stack:\n","        x = down(x)\n","        skips.append(x)\n","\n","    skips = reversed(skips[:-1])\n","\n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        x = tf.keras.layers.Concatenate()([x, skip])\n","\n","    x = last(x)\n","    \n","    return tf.keras.Model(inputs=inputs, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.314766Z","iopub.status.busy":"2023-11-23T10:18:16.314471Z","iopub.status.idle":"2023-11-23T10:18:16.687521Z","shell.execute_reply":"2023-11-23T10:18:16.686563Z","shell.execute_reply.started":"2023-11-23T10:18:16.314715Z"},"papermill":{"duration":0.729444,"end_time":"2023-10-11T09:27:44.742887","exception":false,"start_time":"2023-10-11T09:27:44.013443","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["generator = Generator()\n","tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.689034Z","iopub.status.busy":"2023-11-23T10:18:16.688773Z","iopub.status.idle":"2023-11-23T10:18:16.728064Z","shell.execute_reply":"2023-11-23T10:18:16.727070Z","shell.execute_reply.started":"2023-11-23T10:18:16.689011Z"},"papermill":{"duration":5.788935,"end_time":"2023-10-11T09:27:50.541316","exception":false,"start_time":"2023-10-11T09:27:44.752381","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# -------- PRINT GENERATED IMAGES -------- #\n","\n","gen_output = generator(TR[tf.newaxis, ...], training=False)\n","#plt.imshow(gen_output[0, ...])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.729538Z","iopub.status.busy":"2023-11-23T10:18:16.729220Z","iopub.status.idle":"2023-11-23T10:18:16.741668Z","shell.execute_reply":"2023-11-23T10:18:16.740878Z","shell.execute_reply.started":"2023-11-23T10:18:16.729505Z"},"trusted":true},"outputs":[],"source":["def l1_loss(y_true, y_pred) :    \n","    return tf.reduce_mean(tf.abs(y_true - y_pred))\n","\n","\n","def l2_loss(y_true, y_pred) :\n","    return tf.reduce_mean(tf.square(y_true - y_pred))\n","\n","from keras import backend as K\n","\n","\n","def IoULoss(y_true, y_pred, smooth=1e-6):\n","    # convert the tensor to one-hot for multi-class segmentation\n","    y_true = K.squeeze(y_true, 3)\n","    y_true = tf.cast(y_true, \"int32\")\n","    y_true = tf.one_hot(y_true, 4, axis=-1)\n","    \n","    # cast to float32 datatype\n","    y_true = K.cast(y_true, 'float32')\n","    y_pred = K.cast(y_pred, 'float32')\n","    \n","    #flatten label and prediction tensors\n","    inputs = K.flatten(y_pred)\n","    targets = K.flatten(y_true)\n","    \n","    intersection = K.sum(targets * inputs)\n","    total = K.sum(targets) + K.sum(inputs)\n","    union = total - intersection\n","    \n","    IoU = (intersection + smooth) / (union + smooth)\n","    return 1 - IoU\n","\n","scce_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=False,\n","    reduction='auto')\n","\n","def DiceLoss(y_true, y_pred, smooth=1e-6):\n","        \n","    # convert the tensor to one-hot for multi-class segmentation\n","    y_true = K.squeeze(y_true, 3)\n","    y_true = tf.cast(y_true, \"int32\")\n","    y_true = tf.one_hot(y_true, 4, axis=-1)\n","\n","    # cast to float32 datatype\n","    y_true = K.cast(y_true, 'float32')\n","    y_pred = K.cast(y_pred, 'float32')\n","    \n","    #flatten label and prediction tensors\n","    inputs = K.flatten(y_pred)\n","    targets = K.flatten(y_true)\n","\n","    intersection = K.sum(targets * inputs)\n","    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n","    return 1 - dice"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.743002Z","iopub.status.busy":"2023-11-23T10:18:16.742682Z","iopub.status.idle":"2023-11-23T10:18:16.750637Z","shell.execute_reply":"2023-11-23T10:18:16.749784Z","shell.execute_reply.started":"2023-11-23T10:18:16.742978Z"},"papermill":{"duration":0.028006,"end_time":"2023-10-11T09:27:53.571845","exception":false,"start_time":"2023-10-11T09:27:53.543839","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["generator_loss_object = scce_loss\n","\n","def generator_loss(gen_output, target):\n","    return IoULoss(target, gen_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.752110Z","iopub.status.busy":"2023-11-23T10:18:16.751796Z","iopub.status.idle":"2023-11-23T10:18:16.759226Z","shell.execute_reply":"2023-11-23T10:18:16.758448Z","shell.execute_reply.started":"2023-11-23T10:18:16.752080Z"},"papermill":{"duration":0.076301,"end_time":"2023-10-11T09:27:53.666767","exception":false,"start_time":"2023-10-11T09:27:53.590466","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def validation_step(generator, validation_ds) :\n","    val_error = []\n","    for input_image, target in validation_ds:\n","        gen_output = generator(input_image, training=False)\n","        loss = generator_loss(gen_output, target)\n","        val_error.append(loss)\n","        \n","    return np.mean(val_error)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.760519Z","iopub.status.busy":"2023-11-23T10:18:16.760225Z","iopub.status.idle":"2023-11-23T10:18:16.770543Z","shell.execute_reply":"2023-11-23T10:18:16.769693Z","shell.execute_reply.started":"2023-11-23T10:18:16.760490Z"},"trusted":true},"outputs":[],"source":["def create_mask(pred_mask):\n","    pred_mask = tf.argmax(pred_mask, axis=-1)\n","    pred_mask = pred_mask[..., tf.newaxis]\n","    return pred_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.772121Z","iopub.status.busy":"2023-11-23T10:18:16.771839Z","iopub.status.idle":"2023-11-23T10:18:16.779043Z","shell.execute_reply":"2023-11-23T10:18:16.778289Z","shell.execute_reply.started":"2023-11-23T10:18:16.772098Z"},"papermill":{"duration":0.029447,"end_time":"2023-10-11T09:27:53.716274","exception":false,"start_time":"2023-10-11T09:27:53.686827","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def save_models(string, generator) :\n","    generator.save('models/' + string)\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.780364Z","iopub.status.busy":"2023-11-23T10:18:16.780024Z","iopub.status.idle":"2023-11-23T10:18:16.787392Z","shell.execute_reply":"2023-11-23T10:18:16.786603Z","shell.execute_reply.started":"2023-11-23T10:18:16.780341Z"},"papermill":{"duration":0.030162,"end_time":"2023-10-11T09:27:53.818814","exception":false,"start_time":"2023-10-11T09:27:53.788652","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def generate_images(model, test_input, tar):\n","    prediction = model(test_input, training=False)\n","    mask_prediction = create_mask(prediction)\n","\n","    plt.figure(figsize=(15, 15))\n","\n","    display_list = [test_input[0], tar[0], mask_prediction[0]]\n","    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n","\n","    for i in range(3):\n","        plt.subplot(1, 3, i+1)\n","        plt.title(title[i])\n","        # Getting the pixel values in the [0, 1] range to plot.\n","        plt.imshow(display_list[i])\n","        plt.axis('off')\n","    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.788671Z","iopub.status.busy":"2023-11-23T10:18:16.788365Z","iopub.status.idle":"2023-11-23T10:18:16.796944Z","shell.execute_reply":"2023-11-23T10:18:16.796168Z","shell.execute_reply.started":"2023-11-23T10:18:16.788647Z"},"papermill":{"duration":0.02992,"end_time":"2023-10-11T09:27:53.868153","exception":false,"start_time":"2023-10-11T09:27:53.838233","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def save_images(model, test_input, tar, step):\n","    prediction = model(test_input)#, training=True)\n","    plt.figure(figsize=(15, 15))\n","\n","    display_list = [test_input[0], tar[0], prediction[0]]\n","    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n","\n","    for i in range(3):\n","        plt.subplot(1, 3, i+1)\n","        plt.title(title[i])\n","        # Getting the pixel values in the [0, 1] range to plot.\n","        plt.imshow(display_list[i] * 0.5 + 0.5)\n","        plt.axis('off')\n","        \n","    #plt.show()\n","    filename = 'image_' + str(step) + '.jpg'\n","    plt.savefig(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.807158Z","iopub.status.busy":"2023-11-23T10:18:16.806593Z","iopub.status.idle":"2023-11-23T10:18:16.815641Z","shell.execute_reply":"2023-11-23T10:18:16.814934Z","shell.execute_reply.started":"2023-11-23T10:18:16.807127Z"},"papermill":{"duration":0.034471,"end_time":"2023-10-11T09:27:53.972793","exception":false,"start_time":"2023-10-11T09:27:53.938322","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["summary_writer = tf.summary.create_file_writer(\n","    LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","\n","generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.817379Z","iopub.status.busy":"2023-11-23T10:18:16.816851Z","iopub.status.idle":"2023-11-23T10:18:16.824792Z","shell.execute_reply":"2023-11-23T10:18:16.824055Z","shell.execute_reply.started":"2023-11-23T10:18:16.817349Z"},"papermill":{"duration":0.030412,"end_time":"2023-10-11T09:27:54.023162","exception":false,"start_time":"2023-10-11T09:27:53.992750","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["@tf.function\n","def train_step(input_image, target, step):\n","    with tf.GradientTape() as gen_tape :\n","        gen_output = generator(input_image, training=True)\n","\n","        gen_loss = generator_loss(gen_output, target)\n","\n","    generator_gradients = gen_tape.gradient(gen_loss,\n","                                          generator.trainable_variables)\n","    \n","    generator_optimizer.apply_gradients(zip(generator_gradients,\n","                                          generator.trainable_variables))\n","\n","    with summary_writer.as_default():\n","        tf.summary.scalar(\"scce loss\", gen_loss, step=step//trainingset_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.826078Z","iopub.status.busy":"2023-11-23T10:18:16.825816Z","iopub.status.idle":"2023-11-23T10:18:16.837690Z","shell.execute_reply":"2023-11-23T10:18:16.836938Z","shell.execute_reply.started":"2023-11-23T10:18:16.826056Z"},"papermill":{"duration":0.032289,"end_time":"2023-10-11T09:27:54.074499","exception":false,"start_time":"2023-10-11T09:27:54.042210","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def fit(train_ds, validation_ds, test_ds, steps):\n","    \n","    (example_input, example_target) = next(iter(test_ds.take(1)))\n","    start = time.time()\n","    min_val_error = float(\"inf\")\n","    count = 0\n","    count_stopping = 0\n","    for step, (input_image, target) in train_ds.repeat().take(steps).enumerate():\n","        \n","        if (step) % trainingset_size == 0:\n","            display.clear_output(wait=True)\n","\n","            if step != 0:\n","                print(f'Time taken for {trainingset_size} steps: {time.time()-start:.2f} sec\\n')\n","\n","            start = time.time()\n","\n","            generate_images(generator, example_input, example_target)\n","            print(f\"Epoch: {step//trainingset_size}\")\n","            \n","        train_step(input_image, target, step)\n","        \n","        if ((count +1) % (trainingset_size/4)) == 0 :\n","            \n","            val_error = validation_step(generator, validation_ds)\n","            print(\"val_error : \", val_error, \"   at step : \", count)\n","\n","            if val_error < min_val_error :\n","                print(\"updating min_val_error..\")\n","                count_stopping = 0\n","                                \n","                # the last one has the best performance\n","                min_val_error = val_error\n","                filename = 'best_' + str(count + 1) + '.h5'\n","                save_models(filename, generator)\n","                \n","            else :\n","                count_stopping = count_stopping +1 \n","                \n","        if count_stopping > N_EPOCHS_EARLY_STOPPING :\n","            break\n","            \n","        # Training step\n","        if (step+1) % int(trainingset_size * 0.05) == 0:\n","            print('.', end='', flush=True)\n","               \n","        count = count +1 "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T10:18:16.839028Z","iopub.status.busy":"2023-11-23T10:18:16.838775Z"},"trusted":true},"outputs":[],"source":["fit(train_dataset, validation_dataset, test_dataset, steps= NSTEPS)\n","save_models('last_model_.h5', generator)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3907314,"sourceId":6791975,"sourceType":"datasetVersion"}],"dockerImageVersionId":30580,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"papermill":{"default_parameters":{},"duration":42822.800413,"end_time":"2023-10-11T21:20:47.581977","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-10-11T09:27:04.781564","version":"2.4.0"}},"nbformat":4,"nbformat_minor":4}
