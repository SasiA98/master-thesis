{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-07T10:12:28.744298Z","iopub.status.busy":"2023-12-07T10:12:28.743912Z","iopub.status.idle":"2023-12-07T10:12:32.760954Z","shell.execute_reply":"2023-12-07T10:12:32.759989Z","shell.execute_reply.started":"2023-12-07T10:12:28.744258Z"},"papermill":{"duration":8.87465,"end_time":"2023-10-11T09:27:16.758128","exception":false,"start_time":"2023-10-11T09:27:07.883478","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from matplotlib import pyplot as plt\n","from keras.models import Model\n","import tensorflow_probability as tfp\n","import numpy as np\n","from keras import backend as K\n","from IPython import display\n","import cv2\n","import tensorflow as tf\n","import os\n","import pathlib\n","import time\n","import datetime\n","import glob\n","import gc\n","\n","DATASET_PATH = 'task_2/dataset/processed_hk_norm_unenhanced_aug_iris_dataset_64x240_png/'\n","FEATURE_EXTRACTOR_PATH = 'task_2/cnn-based_dfe/models/best_unet_bs4_dice_loss.h5'\n","\n","# The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\n","BATCH_SIZE = 4\n","\n","IMG_HEIGHT = 64\n","IMG_WIDTH = 240\n","# --------------------------------------------------------------------------------------------------------------- #\n","\n","# data disrtibution \n","\n","# 209 subjects \n","# 150 training   72%\n","# 30 validation  14%\n","# 29 testing     14%\n","\n","training_files = glob.glob(DATASET_PATH + 'train/*.png')\n","test_files = glob.glob(DATASET_PATH + 'test/*.png')\n","test_files.sort()\n","trainingset_size = len(training_files)\n","\n","validation_files = []\n","new_test_files = []\n","len_file = len(test_files[1])\n","\n","i=0\n","for file in test_files:\n","    sub = test_files[i][len_file-11:len_file-8]\n","    if int(sub) <= 180 :\n","        validation_files.append(file)\n","    else :\n","        new_test_files.append(file)\n","    i = i+1\n","\n","\n","validationset_size = len(validation_files)\n","\n","test_files = new_test_files\n","testset_size = len(test_files)\n","\n","DATASET_PATH  = pathlib.Path(DATASET_PATH)\n","\n","# --------------------------------------------------------------------------------------------------------------- #\n","\n","# instead of epochs\n","EPOCHS = 80\n","\n","LAMBDA_P = 100\n","LAMBDA_F = 0.5\n","\n","N_EPOCH_EARLY_STOPPING = 80 # 10 epoch * 8 \n","\n","NSTEPS = trainingset_size * EPOCHS\n","\n","INPUT_CHANNELS = 1\n","OUTPUT_CHANNELS = 1\n","\n","# buffer size is equal to training set size\n","BUFFER_SIZE = trainingset_size\n","\n","# log directory \n","LOG_DIR = \"logs/\" + '_nsteps_' + str(NSTEPS) + '_batchsize_' + str(BATCH_SIZE)  + '/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:32.763740Z","iopub.status.busy":"2023-12-07T10:12:32.762993Z","iopub.status.idle":"2023-12-07T10:12:32.771416Z","shell.execute_reply":"2023-12-07T10:12:32.770325Z","shell.execute_reply.started":"2023-12-07T10:12:32.763702Z"},"papermill":{"duration":0.016547,"end_time":"2023-10-11T09:27:16.781820","exception":false,"start_time":"2023-10-11T09:27:16.765273","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load(image_file):\n","    # Read and decode an image file to a uint8 tensor\n","    image = tf.io.read_file(image_file)\n","    image = tf.io.decode_png(image)\n","        \n","    # Split each image tensor into two tensors:\n","    # - one with a real building facade image\n","    # - one with an architecture label image \n","    w = tf.shape(image)[1]\n","    w = w // 2\n","\n","    input_image = image[:, :w, :]\n","    real_image = image[:, w:, :]\n","\n","    # Convert both images to float32 tensors\n","    input_image = tf.cast(input_image, tf.float32)\n","    real_image = tf.cast(real_image, tf.float32)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:32.773357Z","iopub.status.busy":"2023-12-07T10:12:32.772607Z","iopub.status.idle":"2023-12-07T10:12:32.792697Z","shell.execute_reply":"2023-12-07T10:12:32.791732Z","shell.execute_reply.started":"2023-12-07T10:12:32.773322Z"},"trusted":true},"outputs":[],"source":["def resize(input_image, real_image, height, width):\n","    input_image = tf.image.resize(input_image, [height, width],\n","                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    real_image = tf.image.resize(real_image, [height, width],\n","                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    \n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:32.794675Z","iopub.status.busy":"2023-12-07T10:12:32.794031Z","iopub.status.idle":"2023-12-07T10:12:32.804048Z","shell.execute_reply":"2023-12-07T10:12:32.803043Z","shell.execute_reply.started":"2023-12-07T10:12:32.794640Z"},"trusted":true},"outputs":[],"source":["def normalize(input_image, real_image):\n","    input_image = (input_image / 127.5) - 1\n","    real_image = (real_image / 127.5) - 1\n","\n","    return input_image, real_image\n","\n","def denormalize(input_image, real_image): # to [0, 255]\n","    input_image = (input_image + 1) * 127.5\n","    real_image = (real_image + 1) * 127.5\n","\n","    return real_image\n","\n","def normalize2(input_image, real_image) :\n","    \n","    mean = tf.math.reduce_mean(input_image)\n","    std = tf.math.reduce_std(input_image)\n","    input_image = tf.clip_by_value((input_image - mean) / std, clip_value_min=-1.0, clip_value_max=1.0)\n","\n","    mean = tf.math.reduce_mean(real_image)\n","    std = tf.math.reduce_std(real_image)\n","    real_image = tf.clip_by_value((real_image - mean) / std, clip_value_min=-1.0, clip_value_max=1.0)\n","    \n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:32.806724Z","iopub.status.busy":"2023-12-07T10:12:32.806447Z","iopub.status.idle":"2023-12-07T10:12:32.815253Z","shell.execute_reply":"2023-12-07T10:12:32.814287Z","shell.execute_reply.started":"2023-12-07T10:12:32.806699Z"},"papermill":{"duration":0.014905,"end_time":"2023-10-11T09:27:20.504740","exception":false,"start_time":"2023-10-11T09:27:20.489835","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# augmentation step \n","\n","def random_crop(input_image, real_image):\n","    stacked_image = tf.stack([input_image, real_image], axis=0)\n","    cropped_image = tf.image.random_crop(\n","        stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n","\n","    return cropped_image[0], cropped_image[1]\n","\n","@tf.function()\n","def random_jitter(input_image, real_image):\n","    # Resizing to 84x270\n","    x_jitter_offset = 10\n","    y_jitter_offset = 30\n","    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT + x_jitter_offset, IMG_WIDTH + y_jitter_offset)\n","\n","    # Random cropping back to 64x240\n","    input_image, real_image = random_crop(input_image, real_image)\n","\n","    if tf.random.uniform(()) > 0.5:\n","        # Random mirroring\n","        input_image = tf.image.flip_left_right(input_image)\n","        real_image = tf.image.flip_left_right(real_image)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:32.828978Z","iopub.status.busy":"2023-12-07T10:12:32.828718Z","iopub.status.idle":"2023-12-07T10:12:32.858850Z","shell.execute_reply":"2023-12-07T10:12:32.857961Z","shell.execute_reply.started":"2023-12-07T10:12:32.828955Z"},"trusted":true},"outputs":[],"source":["# Daugman feature extraction algorithm\n","\n","def tf_ProcessSingleChannel(channel):\n","    h = tf.histogram_fixed_width(channel, value_range=(0, 255), nbins=256)\n","\n","    h = tf.cast(h, tf.float32)\n","    pixel_values = tf.range(256, dtype=tf.float32)\n","    \n","    weighted_sum = tf.reduce_sum(pixel_values * h)\n","    total_pixels = tf.reduce_sum(h)\n","    mean_val = weighted_sum / total_pixels\n","\n","    # Compute variance and standard deviation\n","    variance = tf.reduce_sum(((pixel_values - mean_val) ** 2) * h) / total_pixels\n","    std_dev = tf.sqrt(variance)\n","\n","    # Compute Gaussian values\n","    gaussian_vals = (1 / (std_dev * tf.sqrt(2 * np.pi))) * tf.exp(-0.5 * ((pixel_values - mean_val) / std_dev) ** 2)\n","\n","    # Set threshold\n","    threshold = tf.reduce_max(gaussian_vals) * 0.1  # For example, 10% of the maximum\n","\n","    # Find values to eliminate\n","    to_eliminate = gaussian_vals < threshold\n","\n","    ProcessedChannel = tf.identity(channel)  # Create a copy\n","\n","    # Replace values below the threshold\n","    for i in range(len(to_eliminate)):\n","        if to_eliminate[i]:\n","            ProcessedChannel = tf.where(channel == i, mean_val + std_dev, ProcessedChannel)\n","\n","    return ProcessedChannel\n","\n","def tf_GaussHistCut(image):\n","    channels = 1\n","    if len(image.shape) > 2:\n","        _, _, channels = image.shape\n","\n","    if channels == 3:  # RGB image\n","        CorrectedImage = tf.zeros_like(image, dtype=tf.uint8)\n","\n","        for ch in range(channels):\n","            CorrectedImage[:, :, ch] = tf_ProcessSingleChannel(image[:, :, ch])\n","    \n","    else:  # Grayscale image\n","        CorrectedImage = tf_ProcessSingleChannel(image)\n","\n","    return CorrectedImage\n","\n","def tf_rescale(data):\n","    data_min = tf.reduce_min(data)\n","    data_max = tf.reduce_max(data)\n","    return (data - data_min) / (data_max - data_min)\n","\n","def tf_mad_normalize(channel):\n","    mad = tfp.stats.percentile(tf.abs(channel - tfp.stats.percentile(channel, 50)), 50)\n","    is_zero_mad = tf.equal(mad, 0)\n","    channel = tf.where(is_zero_mad, tf.zeros_like(channel), (channel - tfp.stats.percentile(channel, 50)) / mad)\n","    return tf_rescale(channel)\n","\n","def tf_daugman_normalization(AR) : #(image):\n","\n","    #AR, AG, AB = tf.split(image, num_or_size_splits=3, axis=-1)\n","\n","    # Apply GaussHistCut\n","    AR = tf_GaussHistCut(AR)\n","    #AG = tf_GaussHistCut(AG)\n","    #AB = tf_GaussHistCut(AB)\n","\n","    AR = tf_mad_normalize(AR)\n","    #AG = tf_mad_normalize(AG)\n","    #AB = tf_mad_normalize(AB)\n","\n","    # Replace NaN and Inf values with 0\n","    AR = tf.where(tf.math.is_nan(AR) | tf.math.is_inf(AR), tf.zeros_like(AR), AR)\n","    #AG = tf.where(tf.math.is_nan(AG) | tf.math.is_inf(AG), tf.zeros_like(AG), AG)\n","    #AB = tf.where(tf.math.is_nan(AB) | tf.math.is_inf(AB), tf.zeros_like(AB), AB)\n","\n","    # Create the normalized image\n","    #norm_image = tf.concat([AR, AG, AB], axis=-1)\n","\n","    return AR #return norm_image\n","    \n","def tf_gaborconvolve(im, nscale, minWaveLength, mult, sigmaOnf):\n","    rows = IMG_HEIGHT #im.shape[0]\n","    cols = IMG_WIDTH #im.shape[1]\n","    \n","    filtersum = tf.zeros(cols, dtype=tf.float32)\n","    EO = [None] * nscale\n","    \n","    ndata = cols\n","\n","    logGabor = tf.zeros(ndata, dtype=tf.float32)\n","    result = tf.zeros([rows, ndata], dtype=tf.complex128)\n","    \n","    radius = tf.range(0, ndata // 2 + 1, dtype=tf.float64) / (ndata // 2) / 2  # Frequency values 0 - 0.5\n","    zerovalue = tf.cast(tf.constant([1.0]), dtype=tf.float64)\n","    radius = tf.tensor_scatter_nd_update(radius, tf.constant([[0]]), zerovalue)\n","    \n","    wavelength = minWaveLength  # Initialize filter wavelength\n","    \n","    for s in range(nscale):\n","        # Construct the filter - first calculate the radial filter component\n","        fo = 1.0 / wavelength  # Centre frequency of filter\n","        # corresponding to fo\n","        \n","        sum = tf.exp( tf.cast( - tf.pow((tf.math.log(radius/fo)), 2), dtype=tf.float32) / (2 * tf.pow(tf.math.log(sigmaOnf), 2)))\n","\n","\n","        indexes = tf.expand_dims(tf.range(0, sum.shape[0]), axis=1)\n","\n","        logGabor = tf.tensor_scatter_nd_update(logGabor, indexes, sum)\n","        logGabor = tf.tensor_scatter_nd_update(logGabor, tf.constant([[0]]), tf.constant([0.0]))\n","        \n","        filter = logGabor\n","        filtersum = filtersum + filter\n","        \n","        for r in range(rows):\n","            signal = im[r, 0:ndata]\n","            imagefft = tf.signal.fft(tf.cast(signal, dtype=tf.complex128))\n","            filter = tf.cast(filter, dtype=tf.complex128)\n","            result = tf.tensor_scatter_nd_add(result, [tf.constant([r])], [tf.signal.ifft(imagefft * filter)])\n","        \n","        EO[s] = result\n","        wavelength *= mult  # Finally calculate the wavelength of the next filter\n","    \n","    filtersum = tf.signal.fftshift(filtersum)\n","    \n","    return EO, filtersum\n","\n","def tf_encode(polar_array, nscales, minWaveLength, mult, sigmaOnf):\n","    # Convoluzione della regione normalizzata con filtri di Gabor\n","    E0, _ = tf_gaborconvolve(polar_array, nscales, minWaveLength, mult, sigmaOnf)\n","    \n","    H = tf.zeros(E0[0].shape)\n","    for k in range(1, nscales + 1):\n","        E1 = E0[k - 1]\n","\n","        cond_0 = tf.math.logical_and(tf.math.real(E1) <= 0, tf.math.imag(E1) <= 0)\n","        cond_1 = tf.math.logical_and(tf.math.real(E1) <= 0, tf.math.imag(E1) > 0)\n","        cond_2 = tf.math.logical_and(tf.math.real(E1) > 0, tf.math.imag(E1) <= 0)\n","        cond_3 = tf.math.logical_and(tf.math.real(E1) > 0, tf.math.imag(E1) > 0)\n","\n","        H=tf.where(cond_0,0.0,H)\n","        H=tf.where(cond_1,1.0,H)\n","        H=tf.where(cond_2,2.0,H)\n","        H=tf.where(cond_3,3.0,H)\n","\n","    return H\n","\n","def tf_GaborBitStreamSTACKED(AR): #polarImage):\n","\n","    #AR, AG, AB = tf.split(polarImage, num_or_size_splits=3, axis=-1)\n","\n","    nscales = 1\n","    minWaveLength = 24\n","    mult = 1\n","    sigmaOnf = 0.5\n","\n","    TR = tf_encode(tf.squeeze(AR), nscales, minWaveLength, mult, sigmaOnf)\n","    #TG = tf_encode(tf.squeeze(AG), nscales, minWaveLength, mult, sigmaOnf)\n","    #TB = tf_encode(tf.squeeze(AB), nscales, minWaveLength, mult, sigmaOnf)\n","\n","    TR = tf.cast(TR, dtype=tf.uint8)\n","\n","    return tf.expand_dims(TR, axis=2) #return tf.concat([tf.expand_dims(TR, axis=2) , tf.expand_dims(TG, axis=2), tf.expand_dims(TB, axis=2)], axis=-1)\n","\n","def tf_daugman_feature_extractor(inp):\n","    return tf_GaborBitStreamSTACKED(inp)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:32.860265Z","iopub.status.busy":"2023-12-07T10:12:32.859995Z","iopub.status.idle":"2023-12-07T10:12:35.281681Z","shell.execute_reply":"2023-12-07T10:12:35.280779Z","shell.execute_reply.started":"2023-12-07T10:12:32.860241Z"},"trusted":true},"outputs":[],"source":["# printing input image - feature image\n","\n","inp, tar = load(training_files[0])\n","print(training_files[0])\n","\n","inpR,IG,IB = tf.split(inp, num_or_size_splits=3, axis=-1)\n","tarR,TG,TB = tf.split(tar, num_or_size_splits=3, axis=-1)\n","\n","tarR_fi = tf_daugman_feature_extractor(tarR)\n","\n","display_list = [(inpR/255.0), (tarR/255.0), (tarR_fi)]\n","title = ['Input Image', 'Target Image', 'Targe Feature Image']\n","plt.figure(figsize=(15, 15))\n","\n","for i in range(3):\n","    plt.subplot(1, 3, i+1)\n","    plt.title(title[i])\n","    plt.imshow(display_list[i])\n","    #plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:35.283117Z","iopub.status.busy":"2023-12-07T10:12:35.282836Z","iopub.status.idle":"2023-12-07T10:12:35.739401Z","shell.execute_reply":"2023-12-07T10:12:35.738193Z","shell.execute_reply.started":"2023-12-07T10:12:35.283091Z"},"trusted":true},"outputs":[],"source":["norm_inp, norm_tar = normalize2(inpR, tarR)\n","norm_tar_fi = tf_daugman_feature_extractor(norm_tar)\n","\n","display_list = [(norm_inp), (norm_tar), (norm_tar_fi)]\n","title = ['Input Image', 'Target Image', 'Targe Feature Image']\n","plt.figure(figsize=(15, 15))\n","\n","for i in range(2):\n","    plt.subplot(1, 3, i+1)\n","    plt.title(title[i])\n","    plt.imshow(display_list[i])\n","    #plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:35.741424Z","iopub.status.busy":"2023-12-07T10:12:35.740975Z","iopub.status.idle":"2023-12-07T10:12:35.748049Z","shell.execute_reply":"2023-12-07T10:12:35.747199Z","shell.execute_reply.started":"2023-12-07T10:12:35.741390Z"},"papermill":{"duration":0.014732,"end_time":"2023-10-11T09:27:20.547759","exception":false,"start_time":"2023-10-11T09:27:20.533027","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_train(image_file):\n","    input_image, real_image = load(image_file)\n","\n","    norm_input_image, norm_real_image = normalize2(input_image, real_image)\n","    norm_input_image,_,_ = tf.split(norm_input_image, num_or_size_splits=3, axis=-1)\n","    norm_real_image,_,_ = tf.split(norm_real_image, num_or_size_splits=3, axis=-1)\n","\n","    fi_real_image = tf_daugman_feature_extractor(norm_real_image)\n","\n","    return norm_input_image, norm_real_image, fi_real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:35.749661Z","iopub.status.busy":"2023-12-07T10:12:35.749275Z","iopub.status.idle":"2023-12-07T10:12:35.759930Z","shell.execute_reply":"2023-12-07T10:12:35.759068Z","shell.execute_reply.started":"2023-12-07T10:12:35.749620Z"},"papermill":{"duration":0.01435,"end_time":"2023-10-11T09:27:20.569005","exception":false,"start_time":"2023-10-11T09:27:20.554655","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_validation(image_file):\n","    input_image, real_image = load(image_file)\n","\n","    norm_input_image, norm_real_image = normalize2(input_image, real_image)\n","    norm_input_image,_,_ = tf.split(norm_input_image, num_or_size_splits=3, axis=-1)\n","    norm_real_image,_,_ = tf.split(norm_real_image, num_or_size_splits=3, axis=-1)\n","\n","    fi_real_image = tf_daugman_feature_extractor(norm_real_image)\n","\n","    return norm_input_image, norm_real_image, fi_real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:35.761539Z","iopub.status.busy":"2023-12-07T10:12:35.761195Z","iopub.status.idle":"2023-12-07T10:12:35.771196Z","shell.execute_reply":"2023-12-07T10:12:35.770058Z","shell.execute_reply.started":"2023-12-07T10:12:35.761503Z"},"papermill":{"duration":0.014275,"end_time":"2023-10-11T09:27:20.590115","exception":false,"start_time":"2023-10-11T09:27:20.575840","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_test(image_file):\n","    input_image, real_image = load(image_file)\n","\n","    norm_input_image, norm_real_image = normalize2(input_image, real_image)\n","    norm_input_image,_,_ = tf.split(norm_input_image, num_or_size_splits=3, axis=-1)\n","    norm_real_image,_,_ = tf.split(norm_real_image, num_or_size_splits=3, axis=-1)\n","\n","    fi_real_image = tf_daugman_feature_extractor(norm_real_image)\n","\n","    return norm_input_image, norm_real_image, fi_real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:35.772882Z","iopub.status.busy":"2023-12-07T10:12:35.772540Z","iopub.status.idle":"2023-12-07T10:12:39.851018Z","shell.execute_reply":"2023-12-07T10:12:39.850119Z","shell.execute_reply.started":"2023-12-07T10:12:35.772847Z"},"papermill":{"duration":0.869299,"end_time":"2023-10-11T09:27:21.466169","exception":false,"start_time":"2023-10-11T09:27:20.596870","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_dataset = tf.data.Dataset.list_files(str(DATASET_PATH / 'train/*.png'))\n","train_dataset = train_dataset.map(load_image_train,\n","                                  num_parallel_calls=tf.data.AUTOTUNE)\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n","train_dataset = train_dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:39.855851Z","iopub.status.busy":"2023-12-07T10:12:39.855562Z","iopub.status.idle":"2023-12-07T10:12:40.485586Z","shell.execute_reply":"2023-12-07T10:12:40.484784Z","shell.execute_reply.started":"2023-12-07T10:12:39.855825Z"},"papermill":{"duration":0.08507,"end_time":"2023-10-11T09:27:21.558480","exception":false,"start_time":"2023-10-11T09:27:21.473410","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["validation_dataset = tf.data.Dataset.from_tensor_slices(validation_files)\n","validation_dataset = validation_dataset.map(load_image_validation)\n","validation_dataset = validation_dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:40.486861Z","iopub.status.busy":"2023-12-07T10:12:40.486609Z","iopub.status.idle":"2023-12-07T10:12:41.123844Z","shell.execute_reply":"2023-12-07T10:12:41.123060Z","shell.execute_reply.started":"2023-12-07T10:12:40.486838Z"},"papermill":{"duration":0.073422,"end_time":"2023-10-11T09:27:21.639212","exception":false,"start_time":"2023-10-11T09:27:21.565790","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["test_dataset = tf.data.Dataset.from_tensor_slices(test_files)\n","test_dataset = test_dataset.map(load_image_test,\n","                                    num_parallel_calls=tf.data.AUTOTUNE)\n","test_dataset = test_dataset.batch(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:41.131091Z","iopub.status.busy":"2023-12-07T10:12:41.130479Z","iopub.status.idle":"2023-12-07T10:12:41.138307Z","shell.execute_reply":"2023-12-07T10:12:41.137359Z","shell.execute_reply.started":"2023-12-07T10:12:41.131057Z"},"papermill":{"duration":0.017581,"end_time":"2023-10-11T09:27:43.912245","exception":false,"start_time":"2023-10-11T09:27:43.894664","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def downsample(filters, size, apply_batchnorm=True):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    \n","    result = tf.keras.Sequential()\n","    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n","\n","    if apply_batchnorm:\n","        result.add(tf.keras.layers.BatchNormalization())\n","\n","    result.add(tf.keras.layers.LeakyReLU())\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:41.149355Z","iopub.status.busy":"2023-12-07T10:12:41.148528Z","iopub.status.idle":"2023-12-07T10:12:41.160406Z","shell.execute_reply":"2023-12-07T10:12:41.159506Z","shell.execute_reply.started":"2023-12-07T10:12:41.149320Z"},"papermill":{"duration":0.016394,"end_time":"2023-10-11T09:27:43.959065","exception":false,"start_time":"2023-10-11T09:27:43.942671","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def upsample(filters, size, apply_dropout=False):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","\n","    result = tf.keras.Sequential()\n","    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n","                                    padding='same',\n","                                    kernel_initializer=initializer,\n","                                    use_bias=False))\n","\n","    result.add(tf.keras.layers.BatchNormalization())\n","\n","    if apply_dropout:\n","        result.add(tf.keras.layers.Dropout(0.5))\n","\n","    result.add(tf.keras.layers.ReLU())\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:41.171259Z","iopub.status.busy":"2023-12-07T10:12:41.170885Z","iopub.status.idle":"2023-12-07T10:12:41.185212Z","shell.execute_reply":"2023-12-07T10:12:41.184353Z","shell.execute_reply.started":"2023-12-07T10:12:41.171226Z"},"papermill":{"duration":0.017731,"end_time":"2023-10-11T09:27:44.006635","exception":false,"start_time":"2023-10-11T09:27:43.988904","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def Generator():\n","    inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS])\n","\n","    down_stack = [\n","        downsample(64, 4, apply_batchnorm=False), \n","        downsample(128, 4), \n","        downsample(256, 4),  \n","        downsample(512, 4), \n","      ]\n","\n","    up_stack = [\n","        upsample(512, 4, apply_dropout=True),  \n","        upsample(256, 4),\n","        upsample(128, 4), \n","        upsample(64, 4),\n","    ]\n","\n","\n","\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n","                                         strides=2,\n","                                         padding='same',\n","                                         kernel_initializer=initializer,\n","                                         activation='tanh') \n","\n","\n","    # --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- #\n","    x = inputs\n","\n","    # Downsampling through the model\n","    skips = []\n","    for down in down_stack:\n","        x = down(x)\n","        skips.append(x)\n","\n","    skips = reversed(skips[:-1])\n","\n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        x = tf.keras.layers.Concatenate()([x, skip])\n","\n","    x = last(x)\n","    \n","    return tf.keras.Model(inputs=inputs, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:41.186670Z","iopub.status.busy":"2023-12-07T10:12:41.186342Z","iopub.status.idle":"2023-12-07T10:12:41.548352Z","shell.execute_reply":"2023-12-07T10:12:41.547215Z","shell.execute_reply.started":"2023-12-07T10:12:41.186639Z"},"papermill":{"duration":0.729444,"end_time":"2023-10-11T09:27:44.742887","exception":false,"start_time":"2023-10-11T09:27:44.013443","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["generator = Generator()\n","#tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:41.550353Z","iopub.status.busy":"2023-12-07T10:12:41.550001Z","iopub.status.idle":"2023-12-07T10:12:42.790701Z","shell.execute_reply":"2023-12-07T10:12:42.789570Z","shell.execute_reply.started":"2023-12-07T10:12:41.550322Z"},"papermill":{"duration":5.788935,"end_time":"2023-10-11T09:27:50.541316","exception":false,"start_time":"2023-10-11T09:27:44.752381","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# -------- PRINT GENERATED IMAGES -------- #\n","\n","gen_output = generator(norm_inp[tf.newaxis, ...], training=False)\n","print(gen_output.shape)\n","#plt.imshow(gen_output[0, ...])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:42.792461Z","iopub.status.busy":"2023-12-07T10:12:42.792097Z","iopub.status.idle":"2023-12-07T10:12:43.277604Z","shell.execute_reply":"2023-12-07T10:12:43.276584Z","shell.execute_reply.started":"2023-12-07T10:12:42.792431Z"},"trusted":true},"outputs":[],"source":["def l1_loss(y_true, y_pred) : \n","    return tf.reduce_mean(tf.abs(y_true - y_pred))\n","\n","def l2_loss(y_true, y_pred) :\n","    return tf.reduce_mean(tf.square(y_true - y_pred))\n","\n","\n","def DiceLoss(y_true, y_pred, smooth=1e-6):\n","    # convert the tensor to one-hot for multi-class segmentation\n","    y_true = K.squeeze(y_true, 3)\n","    y_true = tf.cast(y_true, \"int32\")\n","    y_true = tf.one_hot(y_true, 4, axis=-1)\n","\n","    # convert the tensor to one-hot for multi-class segmentation\n","    y_pred = K.squeeze(y_pred, 3)\n","    y_pred = tf.cast(y_pred, \"int32\")\n","    y_pred = tf.one_hot(y_pred, 4, axis=-1)\n","    \n","    # cast to float32 datatype\n","    y_true = K.cast(y_true, 'float32')\n","    y_pred = K.cast(y_pred, 'float32')\n","    \n","    #flatten label and prediction tensors\n","    inputs = K.flatten(y_pred)\n","    targets = K.flatten(y_true)\n","\n","    intersection = K.sum(targets * inputs)\n","    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n","    return 1 - dice\n","\n","def IoULoss(y_true, y_pred, smooth=1e-6):\n","    # convert the tensor to one-hot for multi-class segmentation\n","    y_true = K.squeeze(y_true, 3)\n","    y_true = tf.cast(y_true, \"int32\")\n","    y_true = tf.one_hot(y_true, 4, axis=-1)\n","    \n","    \n","    # convert the tensor to one-hot for multi-class segmentation\n","    y_pred = K.squeeze(y_pred, 3)\n","    y_pred = tf.cast(y_pred, \"int32\")\n","    y_pred = tf.one_hot(y_pred, 4, axis=-1)\n","    \n","    \n","    # cast to float32 datatype\n","    y_true = K.cast(y_true, 'float32')\n","    y_pred = K.cast(y_pred, 'float32')\n","    \n","    #flatten label and prediction tensors\n","    inputs = K.flatten(y_pred)\n","    targets = K.flatten(y_true)\n","    \n","    intersection = K.sum(targets * inputs)\n","    total = K.sum(targets) + K.sum(inputs)\n","    union = total - intersection\n","    \n","    IoU = (intersection + smooth) / (union + smooth)\n","    return 1 - IoU\n","\n","scce_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=False,\n","    reduction='auto')\n","\n","# -------- FEATURE EXTRACTOR -------- #\n","\n","feature_extractor = tf.keras.models.load_model(FEATURE_EXTRACTOR_PATH)\n","#feature_extractor.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.279247Z","iopub.status.busy":"2023-12-07T10:12:43.278932Z","iopub.status.idle":"2023-12-07T10:12:43.285348Z","shell.execute_reply":"2023-12-07T10:12:43.284411Z","shell.execute_reply.started":"2023-12-07T10:12:43.279220Z"},"papermill":{"duration":0.028006,"end_time":"2023-10-11T09:27:53.571845","exception":false,"start_time":"2023-10-11T09:27:53.543839","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","def generator_loss(disc_generated_output, gen_output, target, fi_gen_output, fi_target):\n","    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n","    \n","    pw_loss = l1_loss(target, gen_output)\n","    fe_loss = IoULoss(fi_target, fi_gen_output)\n","\n","    total_gen_loss = gan_loss + LAMBDA_P * (pw_loss + (LAMBDA_F * fe_loss))\n","\n","    return total_gen_loss, gan_loss, pw_loss, fe_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.287204Z","iopub.status.busy":"2023-12-07T10:12:43.286798Z","iopub.status.idle":"2023-12-07T10:12:43.299260Z","shell.execute_reply":"2023-12-07T10:12:43.298396Z","shell.execute_reply.started":"2023-12-07T10:12:43.287127Z"},"trusted":true},"outputs":[],"source":["def Discriminator():\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","\n","    inp = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS], name='input_image')\n","    tar = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS], name='target_image')\n","    tar_fi = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS], name='target_feature_image')\n","\n","    x = tf.keras.layers.concatenate([inp, tar, tar_fi])  \n","\n","    down1 = downsample(64, 4, False)(x)  \n","    down2 = downsample(128, 4)(down1) \n","    down3 = downsample(256, 4)(down2)\n","\n","    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)\n","    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n","                                kernel_initializer=initializer,\n","                                use_bias=False)(zero_pad1)  \n","\n","    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n","\n","    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n","\n","    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  \n","\n","    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n","                                kernel_initializer=initializer)(zero_pad2)  \n","\n","    return tf.keras.Model(inputs=[inp, tar, tar_fi], outputs=last)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.300836Z","iopub.status.busy":"2023-12-07T10:12:43.300552Z","iopub.status.idle":"2023-12-07T10:12:43.559397Z","shell.execute_reply":"2023-12-07T10:12:43.558431Z","shell.execute_reply.started":"2023-12-07T10:12:43.300812Z"},"trusted":true},"outputs":[],"source":["discriminator = Discriminator()\n","tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.561172Z","iopub.status.busy":"2023-12-07T10:12:43.560772Z","iopub.status.idle":"2023-12-07T10:12:43.892726Z","shell.execute_reply":"2023-12-07T10:12:43.891798Z","shell.execute_reply.started":"2023-12-07T10:12:43.561117Z"},"trusted":true},"outputs":[],"source":["# -------- PRINT DISCRIMINATOR OUTPUT  -------- #\n","\n","disc_out = discriminator([norm_inp[tf.newaxis, ...], norm_tar[tf.newaxis, ...], norm_tar_fi[tf.newaxis, ...]], training=False)\n","plt.imshow(disc_out[0, ..., -1], vmin=0, vmax=1, cmap='RdBu_r')\n","plt.colorbar()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.894201Z","iopub.status.busy":"2023-12-07T10:12:43.893907Z","iopub.status.idle":"2023-12-07T10:12:43.899536Z","shell.execute_reply":"2023-12-07T10:12:43.898555Z","shell.execute_reply.started":"2023-12-07T10:12:43.894174Z"},"trusted":true},"outputs":[],"source":["def discriminator_loss(disc_real_output, disc_generated_output):\n","    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n","    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n","\n","    total_disc_loss = real_loss + generated_loss\n","\n","    return total_disc_loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_mask(pred_mask):\n","    pred_mask = tf.argmax(pred_mask, axis=-1)\n","    pred_mask = pred_mask[..., tf.newaxis]\n","    return pred_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.901021Z","iopub.status.busy":"2023-12-07T10:12:43.900734Z","iopub.status.idle":"2023-12-07T10:12:43.913868Z","shell.execute_reply":"2023-12-07T10:12:43.912982Z","shell.execute_reply.started":"2023-12-07T10:12:43.900977Z"},"papermill":{"duration":0.076301,"end_time":"2023-10-11T09:27:53.666767","exception":false,"start_time":"2023-10-11T09:27:53.590466","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def validation_step(generator, validation_ds) :\n","    val_error = []\n","    pw_error = []\n","    fe_error = []\n","    gan_error = []\n","    \n","    for input_image, target, fi_target in validation_ds:\n","        gen_output = generator(input_image, training=False)\n","\n","        fi_gen_output = feature_extractor(gen_output)\n","        fi_gen_output = create_mask(fi_gen_output)\n","        disc_generated_output = discriminator([input_image, gen_output, fi_gen_output], training=False)\n","\n","        total_val_loss, ganloss, pw_loss, fe_loss =  generator_loss(disc_generated_output, gen_output, target, fi_gen_output, fi_target)\n","\n","        pw_error.append(pw_loss)\n","        fe_error.append(fe_loss)\n","        val_error.append(total_val_loss)\n","        gan_error.append(ganloss)\n","        \n","    return np.mean(val_error), np.mean(gan_error), np.mean(pw_error), np.mean(fe_error)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.915940Z","iopub.status.busy":"2023-12-07T10:12:43.915188Z","iopub.status.idle":"2023-12-07T10:12:43.923339Z","shell.execute_reply":"2023-12-07T10:12:43.922440Z","shell.execute_reply.started":"2023-12-07T10:12:43.915906Z"},"papermill":{"duration":0.029447,"end_time":"2023-10-11T09:27:53.716274","exception":false,"start_time":"2023-10-11T09:27:53.686827","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def save_models(string, generator) :\n","    generator.save('models/' + string)\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.933958Z","iopub.status.busy":"2023-12-07T10:12:43.933640Z","iopub.status.idle":"2023-12-07T10:12:43.947739Z","shell.execute_reply":"2023-12-07T10:12:43.946877Z","shell.execute_reply.started":"2023-12-07T10:12:43.933927Z"},"papermill":{"duration":0.032911,"end_time":"2023-10-11T09:27:53.769057","exception":false,"start_time":"2023-10-11T09:27:53.736146","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["generator_optimizer = tf.keras.optimizers.Adam(2e-3, beta_1=0.5)\n","discriminator_optimizer = tf.keras.optimizers.Adam(1e-5, beta_1=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.949826Z","iopub.status.busy":"2023-12-07T10:12:43.948995Z","iopub.status.idle":"2023-12-07T10:12:43.957832Z","shell.execute_reply":"2023-12-07T10:12:43.956953Z","shell.execute_reply.started":"2023-12-07T10:12:43.949792Z"},"papermill":{"duration":0.030162,"end_time":"2023-10-11T09:27:53.818814","exception":false,"start_time":"2023-10-11T09:27:53.788652","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def generate_images(model, test_input, tar_input, tar_fi):\n","    prediction = model(test_input, training=False)\n","    fi_gen = feature_extractor(prediction)\n","    mask_prediction = create_mask(fi_gen)\n","    \n","    plt.figure(figsize=(15, 15))\n","\n","    display_list = [(test_input[0]*0.5 + 0.5), mask_prediction[0], tar_fi[0], (prediction[0]*0.5 + 0.5), (tar_input[0]*0.5 + 0.5)]\n","    title = ['Input Image', 'Prediction FI', 'Ground Truth FI', 'Predicted Image', 'Ground Truth']\n","\n","    for i in range(5):\n","        plt.subplot(1, 5, i+1)\n","        plt.title(title[i])\n","        # Getting the pixel values in the [0, 1] range to plot.\n","        plt.imshow(display_list[i])\n","        plt.axis('off')\n","    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.959341Z","iopub.status.busy":"2023-12-07T10:12:43.959065Z","iopub.status.idle":"2023-12-07T10:12:43.971872Z","shell.execute_reply":"2023-12-07T10:12:43.971036Z","shell.execute_reply.started":"2023-12-07T10:12:43.959318Z"},"papermill":{"duration":0.02992,"end_time":"2023-10-11T09:27:53.868153","exception":false,"start_time":"2023-10-11T09:27:53.838233","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def save_images(model, test_input, tar_input, tar_fi, step):\n","    prediction = model(test_input, training=False)\n","    fi_gen = feature_extractor(prediction)\n","    mask_prediction = create_mask(fi_gen)\n","    \n","    plt.figure(figsize=(15, 15))\n","\n","    display_list = [(test_input[0]*0.5 + 0.5), mask_prediction[0], tar_fi[0], (prediction[0]*0.5 + 0.5), (tar_input[0]*0.5 + 0.5)]\n","    title = ['Input Image', 'Prediction FI', 'Ground Truth FI', 'Predicted Image', 'Ground Truth']\n","\n","    for i in range(5):\n","        plt.subplot(1, 5, i+1)\n","        plt.title(title[i])\n","        # Getting the pixel values in the [0, 1] range to plot.\n","        plt.imshow(display_list[i])\n","        plt.axis('off')\n","        \n","    #plt.show()\n","    filename = 'image_' + str(step) + '.jpg'\n","    plt.savefig(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.973455Z","iopub.status.busy":"2023-12-07T10:12:43.973113Z","iopub.status.idle":"2023-12-07T10:12:43.983899Z","shell.execute_reply":"2023-12-07T10:12:43.982982Z","shell.execute_reply.started":"2023-12-07T10:12:43.973424Z"},"papermill":{"duration":0.034471,"end_time":"2023-10-11T09:27:53.972793","exception":false,"start_time":"2023-10-11T09:27:53.938322","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["summary_writer = tf.summary.create_file_writer(\n","    LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.985380Z","iopub.status.busy":"2023-12-07T10:12:43.985061Z","iopub.status.idle":"2023-12-07T10:12:43.997079Z","shell.execute_reply":"2023-12-07T10:12:43.996202Z","shell.execute_reply.started":"2023-12-07T10:12:43.985355Z"},"papermill":{"duration":0.030412,"end_time":"2023-10-11T09:27:54.023162","exception":false,"start_time":"2023-10-11T09:27:53.992750","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["@tf.function\n","def train_step(input_image, target, fi_target, step, pw_val_error, fe_val_error, gan_val_loss, gen_total_val_loss):\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        gen_output = generator(input_image, training=True)\n","        fi_gen_output = feature_extractor(gen_output)\n","        mask_fi_gen_output = create_mask(fi_gen_output)\n","\n","        disc_real_output = discriminator([input_image, target, fi_target], training=True)\n","        disc_generated_output = discriminator([input_image, gen_output, mask_fi_gen_output], training=True)\n","\n","        gen_total_loss, gan_loss, pw_loss, fe_error = generator_loss(disc_generated_output, gen_output, target, mask_fi_gen_output, fi_target)\n","        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n","\n","    generator_gradients = gen_tape.gradient(gen_total_loss,\n","                                          generator.trainable_variables)\n","    \n","    discriminator_gradients = disc_tape.gradient(disc_loss,\n","                                               discriminator.trainable_variables)\n","    \n","    generator_optimizer.apply_gradients(zip(generator_gradients,\n","                                          generator.trainable_variables))\n","    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n","                                              discriminator.trainable_variables))\n","\n","    with summary_writer.as_default():\n","        tf.summary.scalar('pw_loss', pw_loss, step=step//trainingset_size)\n","        tf.summary.scalar('fe_error', fe_error, step=step//trainingset_size)\n","        tf.summary.scalar('gan_loss', gan_loss, step=step//trainingset_size)\n","        tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//trainingset_size)\n","        tf.summary.scalar('disc_loss', disc_loss, step=step//trainingset_size)\n","\n","        \n","        tf.summary.scalar('pw_validation_loss', pw_val_error, step=step//trainingset_size)\n","        tf.summary.scalar('fe_validation_loss', fe_val_error, step=step//trainingset_size)\n","        tf.summary.scalar('gan_validation_loss', gan_val_loss, step=step//trainingset_size)\n","        tf.summary.scalar('gen_total_validation_loss', gen_total_val_loss, step=step//trainingset_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:43.999371Z","iopub.status.busy":"2023-12-07T10:12:43.998666Z","iopub.status.idle":"2023-12-07T10:12:44.015387Z","shell.execute_reply":"2023-12-07T10:12:44.014398Z","shell.execute_reply.started":"2023-12-07T10:12:43.999337Z"},"papermill":{"duration":0.032289,"end_time":"2023-10-11T09:27:54.074499","exception":false,"start_time":"2023-10-11T09:27:54.042210","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def fit(train_ds, validation_ds, test_ds, steps):\n","    \n","    example_input, example_target, example_fi_target = next(iter(test_ds.take(1)))\n","    start = time.time()\n","    min_val_error = float(\"inf\")\n","    gen_total_val_loss =float(\"inf\")\n","    pw_val_error = float(\"inf\")\n","    fe_val_error = float(\"inf\")\n","    gan_val_loss = float(\"inf\")\n","    count = 0\n","    count_stopping = 0\n","    \n","    for step, (input_image, target, fi_target) in train_ds.repeat().take(steps).enumerate():\n","        \n","        if (step) % trainingset_size == 0:\n","            #display.clear_output(wait=True)\n","\n","            if step != 0:\n","                print(f'Time taken for {trainingset_size} steps: {time.time()-start:.2f} sec\\n')\n","\n","            start = time.time()\n","\n","            generate_images(generator, example_input, example_target, example_fi_target)\n","            print(f\"Epoch: {step//trainingset_size}\")\n","\n","        train_step(input_image, target, fi_target, step, pw_val_error, fe_val_error, gan_val_loss, gen_total_val_loss)\n","\n","        if ((count +1) % (trainingset_size/4)) == 0 : \n","            gen_total_val_loss, gan_val_loss, pw_val_error, fe_val_error = validation_step(generator, validation_ds)\n","            print(\"gen_total_val_loss : \", gen_total_val_loss, \"   at step : \", count)\n","            print(\"gen_val_loss : \", gan_val_loss, \"   at step : \", count)\n","            print(\"pw_val_error : \", pw_val_error, \"   at step : \", count)\n","            print(\"fe_val_error : \", fe_val_error, \"   at step : \", count)\n","\n","            if gen_total_val_loss < min_val_error :\n","                print(\"updating min_val_error..\")\n","                count_stopping = 0\n","                min_val_error = gen_total_val_loss\n","\n","                filename = 'best_' + str(count + 1) + '.h5'\n","                save_images(generator, example_input, example_target,example_fi_target, count+1)\n","                save_models(filename, generator)\n","            else :\n","                count_stopping = count_stopping +1 \n","                \n","        if count_stopping > N_EPOCH_EARLY_STOPPING :\n","            break\n","                \n","        # Training step\n","        if (step+1) % int(trainingset_size * 0.05) == 0:\n","            print('.', end='', flush=True)\n","                           \n","        count = count +1 "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-07T10:12:44.017333Z","iopub.status.busy":"2023-12-07T10:12:44.017028Z","iopub.status.idle":"2023-12-07T14:48:28.058930Z","shell.execute_reply":"2023-12-07T14:48:28.057637Z","shell.execute_reply.started":"2023-12-07T10:12:44.017309Z"},"papermill":{"duration":42769.891539,"end_time":"2023-10-11T21:20:43.984902","exception":false,"start_time":"2023-10-11T09:27:54.093363","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["fit(train_dataset, validation_dataset, test_dataset, steps= NSTEPS)\n","save_models('last_model_.h5', generator)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4020825,"sourceId":6995164,"sourceType":"datasetVersion"},{"datasetId":4137513,"sourceId":7163005,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
