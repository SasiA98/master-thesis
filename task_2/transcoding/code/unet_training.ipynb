{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-18T10:45:49.319559Z","iopub.status.busy":"2023-11-18T10:45:49.319208Z","iopub.status.idle":"2023-11-18T10:46:02.609508Z","shell.execute_reply":"2023-11-18T10:46:02.608467Z","shell.execute_reply.started":"2023-11-18T10:45:49.319527Z"},"papermill":{"duration":8.87465,"end_time":"2023-10-11T09:27:16.758128","exception":false,"start_time":"2023-10-11T09:27:07.883478","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from matplotlib import pyplot as plt\n","from keras.models import Model\n","import tensorflow_probability as tfp\n","import numpy as np\n","from IPython import display\n","from keras import backend as K\n","import cv2\n","import tensorflow as tf\n","import os\n","import pathlib\n","import time\n","import datetime\n","import glob\n","import gc\n","\n","DATASET_PATH = 'task_2/dataset/processed_hk_norm_unenhanced_aug_iris_dataset_64x240_png/'\n","FEATURE_EXTRACTOR_PATH = 'task_2/cnn-based_dfe/models/best_unet_bs4_dice_loss.h5'\n","\n","\n","BATCH_SIZE = 1\n","\n","IMG_HEIGHT = 64\n","IMG_WIDTH = 240\n","# --------------------------------------------------------------------------------------------------------------- #\n","\n","# data disrtibution \n","\n","# 209 subjects \n","# 150 training   72%\n","# 30 validation  14%\n","# 29 testing     14%\n","\n","training_files = glob.glob(DATASET_PATH + 'train/*.png')\n","test_files = glob.glob(DATASET_PATH + 'test/*.png')\n","test_files.sort()\n","trainingset_size = len(training_files)\n","\n","validation_files = []\n","new_test_files = []\n","len_file = len(test_files[1])\n","\n","i=0\n","for file in test_files:\n","    sub = test_files[i][len_file-11:len_file-8]\n","    if int(sub) <= 180 :\n","        validation_files.append(file)\n","    else :\n","        new_test_files.append(file)\n","    i = i+1\n","\n","\n","validationset_size = len(validation_files)\n","\n","test_files = new_test_files\n","testset_size = len(test_files)\n","\n","DATASET_PATH  = pathlib.Path(DATASET_PATH)\n","\n","# --------------------------------------------------------------------------------------------------------------- #\n","\n","# instead of epochs\n","EPOCHS = 300\n","\n","LAMBDA_F = 1\n","N_EPOCH_EARLY_STOPPING = 60 \n","\n","NSTEPS = trainingset_size * EPOCHS\n","\n","INPUT_CHANNELS = 1\n","OUTPUT_CHANNELS = 1\n","\n","# buffer size is equal to training set size\n","BUFFER_SIZE = trainingset_size\n","\n","# log directory \n","LOG_DIR = \"logs/\" + '_nsteps_' + str(NSTEPS) + '_batchsize_' + str(BATCH_SIZE)  + '/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:02.611934Z","iopub.status.busy":"2023-11-18T10:46:02.611355Z","iopub.status.idle":"2023-11-18T10:46:02.617968Z","shell.execute_reply":"2023-11-18T10:46:02.617099Z","shell.execute_reply.started":"2023-11-18T10:46:02.611905Z"},"papermill":{"duration":0.016547,"end_time":"2023-10-11T09:27:16.781820","exception":false,"start_time":"2023-10-11T09:27:16.765273","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load(image_file):\n","    # Read and decode an image file to a uint8 tensor\n","    image = tf.io.read_file(image_file)\n","    image = tf.io.decode_png(image)\n","        \n","    # Split each image tensor into two tensors:\n","    # - one with a real building facade image\n","    # - one with an architecture label image \n","    w = tf.shape(image)[1]\n","    w = w // 2\n","\n","    input_image = image[:, :w, :]\n","    real_image = image[:, w:, :]\n","\n","    # Convert both images to float32 tensors\n","    input_image = tf.cast(input_image, tf.float32)\n","    real_image = tf.cast(real_image, tf.float32)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:02.620026Z","iopub.status.busy":"2023-11-18T10:46:02.619065Z","iopub.status.idle":"2023-11-18T10:46:02.647237Z","shell.execute_reply":"2023-11-18T10:46:02.646203Z","shell.execute_reply.started":"2023-11-18T10:46:02.619992Z"},"trusted":true},"outputs":[],"source":["def resize(input_image, real_image, height, width):\n","    input_image = tf.image.resize(input_image, [height, width],\n","                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    real_image = tf.image.resize(real_image, [height, width],\n","                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    \n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:02.651051Z","iopub.status.busy":"2023-11-18T10:46:02.650204Z","iopub.status.idle":"2023-11-18T10:46:02.659862Z","shell.execute_reply":"2023-11-18T10:46:02.658761Z","shell.execute_reply.started":"2023-11-18T10:46:02.651014Z"},"trusted":true},"outputs":[],"source":["def normalize(input_image, real_image):\n","    input_image = (input_image / 127.5) - 1\n","    real_image = (real_image / 127.5) - 1\n","\n","    return input_image, real_image\n","\n","def denormalize(input_image, real_image): # to [0, 255]\n","    input_image = (input_image + 1) * 127.5\n","    real_image = (real_image + 1) * 127.5\n","\n","    return real_image\n","\n","def normalize2(input_image, real_image) :\n","    \n","    mean = tf.math.reduce_mean(input_image)\n","    std = tf.math.reduce_std(input_image)\n","    input_image = tf.clip_by_value((input_image - mean) / std, clip_value_min=-1.0, clip_value_max=1.0)\n","\n","    mean = tf.math.reduce_mean(real_image)\n","    std = tf.math.reduce_std(real_image)\n","    real_image = tf.clip_by_value((real_image - mean) / std, clip_value_min=-1.0, clip_value_max=1.0)\n","    \n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:02.661845Z","iopub.status.busy":"2023-11-18T10:46:02.661311Z","iopub.status.idle":"2023-11-18T10:46:02.671872Z","shell.execute_reply":"2023-11-18T10:46:02.670755Z","shell.execute_reply.started":"2023-11-18T10:46:02.661810Z"},"papermill":{"duration":0.014905,"end_time":"2023-10-11T09:27:20.504740","exception":false,"start_time":"2023-10-11T09:27:20.489835","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# augmentation step \n","\n","def random_crop(input_image, real_image):\n","    stacked_image = tf.stack([input_image, real_image], axis=0)\n","    cropped_image = tf.image.random_crop(\n","        stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n","\n","    return cropped_image[0], cropped_image[1]\n","\n","@tf.function()\n","def random_jitter(input_image, real_image):\n","    # Resizing to 74x270\n","    x_jitter_offset = 10\n","    y_jitter_offset = 30\n","    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT + x_jitter_offset, IMG_WIDTH + y_jitter_offset)\n","\n","    # Random cropping back to 64x240\n","    input_image, real_image = random_crop(input_image, real_image)\n","\n","    if tf.random.uniform(()) > 0.5:\n","        # Random mirroring\n","        input_image = tf.image.flip_left_right(input_image)\n","        real_image = tf.image.flip_left_right(real_image)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:02.674047Z","iopub.status.busy":"2023-11-18T10:46:02.673277Z","iopub.status.idle":"2023-11-18T10:46:02.705292Z","shell.execute_reply":"2023-11-18T10:46:02.704002Z","shell.execute_reply.started":"2023-11-18T10:46:02.674014Z"},"trusted":true},"outputs":[],"source":["# Daugman feature extraction algorithm\n","\n","def tf_ProcessSingleChannel(channel):\n","    h = tf.histogram_fixed_width(channel, value_range=(0, 255), nbins=256)\n","\n","    h = tf.cast(h, tf.float32)\n","    pixel_values = tf.range(256, dtype=tf.float32)\n","    \n","    weighted_sum = tf.reduce_sum(pixel_values * h)\n","    total_pixels = tf.reduce_sum(h)\n","    mean_val = weighted_sum / total_pixels\n","\n","    # Compute variance and standard deviation\n","    variance = tf.reduce_sum(((pixel_values - mean_val) ** 2) * h) / total_pixels\n","    std_dev = tf.sqrt(variance)\n","\n","    # Compute Gaussian values\n","    gaussian_vals = (1 / (std_dev * tf.sqrt(2 * np.pi))) * tf.exp(-0.5 * ((pixel_values - mean_val) / std_dev) ** 2)\n","\n","    # Set threshold\n","    threshold = tf.reduce_max(gaussian_vals) * 0.1  # For example, 10% of the maximum\n","\n","    # Find values to eliminate\n","    to_eliminate = gaussian_vals < threshold\n","\n","    ProcessedChannel = tf.identity(channel)  # Create a copy\n","\n","    # Replace values below the threshold\n","    for i in range(len(to_eliminate)):\n","        if to_eliminate[i]:\n","            ProcessedChannel = tf.where(channel == i, mean_val + std_dev, ProcessedChannel)\n","\n","    return ProcessedChannel\n","\n","def tf_GaussHistCut(image):\n","    channels = 1\n","    if len(image.shape) > 2:\n","        _, _, channels = image.shape\n","\n","    if channels == 3:  # RGB image\n","        CorrectedImage = tf.zeros_like(image, dtype=tf.uint8)\n","\n","        for ch in range(channels):\n","            CorrectedImage[:, :, ch] = tf_ProcessSingleChannel(image[:, :, ch])\n","    \n","    else:  # Grayscale image\n","        CorrectedImage = tf_ProcessSingleChannel(image)\n","\n","    return CorrectedImage\n","\n","def tf_rescale(data):\n","    data_min = tf.reduce_min(data)\n","    data_max = tf.reduce_max(data)\n","    return (data - data_min) / (data_max - data_min)\n","\n","def tf_mad_normalize(channel):\n","    mad = tfp.stats.percentile(tf.abs(channel - tfp.stats.percentile(channel, 50)), 50)\n","    is_zero_mad = tf.equal(mad, 0)\n","    channel = tf.where(is_zero_mad, tf.zeros_like(channel), (channel - tfp.stats.percentile(channel, 50)) / mad)\n","    return tf_rescale(channel)\n","\n","def tf_daugman_normalization(AR) : #(image):\n","\n","    #AR, AG, AB = tf.split(image, num_or_size_splits=3, axis=-1)\n","\n","    # Apply GaussHistCut\n","    AR = tf_GaussHistCut(AR)\n","    #AG = tf_GaussHistCut(AG)\n","    #AB = tf_GaussHistCut(AB)\n","\n","    AR = tf_mad_normalize(AR)\n","    #AG = tf_mad_normalize(AG)\n","    #AB = tf_mad_normalize(AB)\n","\n","    # Replace NaN and Inf values with 0\n","    AR = tf.where(tf.math.is_nan(AR) | tf.math.is_inf(AR), tf.zeros_like(AR), AR)\n","    #AG = tf.where(tf.math.is_nan(AG) | tf.math.is_inf(AG), tf.zeros_like(AG), AG)\n","    #AB = tf.where(tf.math.is_nan(AB) | tf.math.is_inf(AB), tf.zeros_like(AB), AB)\n","\n","    # Create the normalized image\n","    #norm_image = tf.concat([AR, AG, AB], axis=-1)\n","\n","    return AR #return norm_image\n","    \n","def tf_gaborconvolve(im, nscale, minWaveLength, mult, sigmaOnf):\n","    rows = IMG_HEIGHT #im.shape[0]\n","    cols = IMG_WIDTH #im.shape[1]\n","    \n","    filtersum = tf.zeros(cols, dtype=tf.float32)\n","    EO = [None] * nscale\n","    \n","    ndata = cols\n","\n","    logGabor = tf.zeros(ndata, dtype=tf.float32)\n","    result = tf.zeros([rows, ndata], dtype=tf.complex128)\n","    \n","    radius = tf.range(0, ndata // 2 + 1, dtype=tf.float64) / (ndata // 2) / 2  # Frequency values 0 - 0.5\n","    zerovalue = tf.cast(tf.constant([1.0]), dtype=tf.float64)\n","    radius = tf.tensor_scatter_nd_update(radius, tf.constant([[0]]), zerovalue)\n","    \n","    wavelength = minWaveLength  # Initialize filter wavelength\n","    \n","    for s in range(nscale):\n","        # Construct the filter - first calculate the radial filter component\n","        fo = 1.0 / wavelength  # Centre frequency of filter\n","        # corresponding to fo\n","        \n","        sum = tf.exp( tf.cast( - tf.pow((tf.math.log(radius/fo)), 2), dtype=tf.float32) / (2 * tf.pow(tf.math.log(sigmaOnf), 2)))\n","\n","\n","        indexes = tf.expand_dims(tf.range(0, sum.shape[0]), axis=1)\n","\n","        logGabor = tf.tensor_scatter_nd_update(logGabor, indexes, sum)\n","        logGabor = tf.tensor_scatter_nd_update(logGabor, tf.constant([[0]]), tf.constant([0.0]))\n","        \n","        filter = logGabor\n","        filtersum = filtersum + filter\n","        \n","        for r in range(rows):\n","            signal = im[r, 0:ndata]\n","            imagefft = tf.signal.fft(tf.cast(signal, dtype=tf.complex128))\n","            filter = tf.cast(filter, dtype=tf.complex128)\n","            result = tf.tensor_scatter_nd_add(result, [tf.constant([r])], [tf.signal.ifft(imagefft * filter)])\n","        \n","        EO[s] = result\n","        wavelength *= mult  # Finally calculate the wavelength of the next filter\n","    \n","    filtersum = tf.signal.fftshift(filtersum)\n","    \n","    return EO, filtersum\n","\n","def tf_encode(polar_array, nscales, minWaveLength, mult, sigmaOnf):\n","    # Convoluzione della regione normalizzata con filtri di Gabor\n","    E0, _ = tf_gaborconvolve(polar_array, nscales, minWaveLength, mult, sigmaOnf)\n","    \n","    H = tf.zeros(E0[0].shape)\n","    for k in range(1, nscales + 1):\n","        E1 = E0[k - 1]\n","\n","        cond_0 = tf.math.logical_and(tf.math.real(E1) <= 0, tf.math.imag(E1) <= 0)\n","        cond_1 = tf.math.logical_and(tf.math.real(E1) <= 0, tf.math.imag(E1) > 0)\n","        cond_2 = tf.math.logical_and(tf.math.real(E1) > 0, tf.math.imag(E1) <= 0)\n","        cond_3 = tf.math.logical_and(tf.math.real(E1) > 0, tf.math.imag(E1) > 0)\n","\n","        H=tf.where(cond_0,0.0,H)\n","        H=tf.where(cond_1,1.0,H)\n","        H=tf.where(cond_2,2.0,H)\n","        H=tf.where(cond_3,3.0,H)\n","\n","    return H\n","\n","def tf_GaborBitStreamSTACKED(AR): #polarImage):\n","\n","    #AR, AG, AB = tf.split(polarImage, num_or_size_splits=3, axis=-1)\n","\n","    nscales = 1\n","    minWaveLength = 24\n","    mult = 1\n","    sigmaOnf = 0.5\n","\n","    TR = tf_encode(tf.squeeze(AR), nscales, minWaveLength, mult, sigmaOnf)\n","    #TG = tf_encode(tf.squeeze(AG), nscales, minWaveLength, mult, sigmaOnf)\n","    #TB = tf_encode(tf.squeeze(AB), nscales, minWaveLength, mult, sigmaOnf)\n","\n","    TR = tf.cast(TR, dtype=tf.uint8)\n","\n","    return tf.expand_dims(TR, axis=2) #return tf.concat([tf.expand_dims(TR, axis=2) , tf.expand_dims(TG, axis=2), tf.expand_dims(TB, axis=2)], axis=-1)\n","\n","def tf_daugman_feature_extractor(inp):\n","    return tf_GaborBitStreamSTACKED(inp)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:02.707283Z","iopub.status.busy":"2023-11-18T10:46:02.706840Z","iopub.status.idle":"2023-11-18T10:46:05.612305Z","shell.execute_reply":"2023-11-18T10:46:05.611224Z","shell.execute_reply.started":"2023-11-18T10:46:02.707246Z"},"trusted":true},"outputs":[],"source":["# printing input image - feature image\n","\n","inp, tar = load(training_files[0])\n","#print(training_files[0])\n","\n","inpR,IG,IB = tf.split(inp, num_or_size_splits=3, axis=-1)\n","tarR,TG,TB = tf.split(tar, num_or_size_splits=3, axis=-1)\n","\n","display_list = [(inpR/255.0), (tarR/255.0)]\n","title = ['Input Image', 'Target Image']\n","plt.figure(figsize=(15, 15))\n","\n","for i in range(2):\n","    plt.subplot(1, 2, i+1)\n","    plt.title(title[i])\n","    plt.imshow(display_list[i])\n","    #plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:05.614064Z","iopub.status.busy":"2023-11-18T10:46:05.613661Z","iopub.status.idle":"2023-11-18T10:46:06.124255Z","shell.execute_reply":"2023-11-18T10:46:06.123321Z","shell.execute_reply.started":"2023-11-18T10:46:05.614028Z"},"trusted":true},"outputs":[],"source":["inp, tar = load(training_files[0])\n","#print(test_files[0])\n","\n","inpR,IG,IB = tf.split(inp, num_or_size_splits=3, axis=-1)\n","tarR,TG,TB = tf.split(tar, num_or_size_splits=3, axis=-1)\n","\n","norm_inp, norm_tar = normalize2(inpR, tarR)\n","\n","norm_inp = np.concatenate((norm_inp, norm_inp, norm_inp), axis=2)\n","norm_tar = np.concatenate((norm_tar, norm_tar, norm_tar), axis=2)\n","\n","display_list = [(norm_inp), (norm_tar)]\n","title = ['input_image', 'target_image']\n","plt.figure(figsize=(15, 15))\n","\n","for i in range(2):\n","    plt.subplot(1, 2, i+1)\n","    plt.title(title[i])\n","    plt.imshow(display_list[i]*0.5 + 0.5)\n","    #plt.axis('off')\n","\n","plt.show()\n","#plt.savefig('/Users/salvatoreamodio/Desktop/normalized_iris_image.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:06.125820Z","iopub.status.busy":"2023-11-18T10:46:06.125417Z","iopub.status.idle":"2023-11-18T10:46:06.131564Z","shell.execute_reply":"2023-11-18T10:46:06.130690Z","shell.execute_reply.started":"2023-11-18T10:46:06.125792Z"},"papermill":{"duration":0.014732,"end_time":"2023-10-11T09:27:20.547759","exception":false,"start_time":"2023-10-11T09:27:20.533027","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_train(image_file):\n","    input_image, real_image = load(image_file)\n","    norm_input_image, norm_real_image = normalize2(input_image, real_image)\n","    norm_input_image,_,_ = tf.split(norm_input_image, num_or_size_splits=3, axis=-1)\n","    norm_real_image,_,_ = tf.split(norm_real_image, num_or_size_splits=3, axis=-1)\n","\n","    fi_real_image = tf_daugman_feature_extractor(norm_real_image)\n","    return norm_input_image, norm_real_image, fi_real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:06.132913Z","iopub.status.busy":"2023-11-18T10:46:06.132617Z","iopub.status.idle":"2023-11-18T10:46:06.233159Z","shell.execute_reply":"2023-11-18T10:46:06.232233Z","shell.execute_reply.started":"2023-11-18T10:46:06.132889Z"},"papermill":{"duration":0.01435,"end_time":"2023-10-11T09:27:20.569005","exception":false,"start_time":"2023-10-11T09:27:20.554655","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_validation(image_file):\n","    input_image, real_image = load(image_file)\n","\n","    norm_input_image, norm_real_image = normalize2(input_image, real_image)\n","    norm_input_image,_,_ = tf.split(norm_input_image, num_or_size_splits=3, axis=-1)\n","    norm_real_image,_,_ = tf.split(norm_real_image, num_or_size_splits=3, axis=-1)\n","\n","    fi_real_image = tf_daugman_feature_extractor(norm_real_image)\n","    return norm_input_image, norm_real_image, fi_real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:06.237800Z","iopub.status.busy":"2023-11-18T10:46:06.237419Z","iopub.status.idle":"2023-11-18T10:46:06.243872Z","shell.execute_reply":"2023-11-18T10:46:06.242967Z","shell.execute_reply.started":"2023-11-18T10:46:06.237744Z"},"papermill":{"duration":0.014275,"end_time":"2023-10-11T09:27:20.590115","exception":false,"start_time":"2023-10-11T09:27:20.575840","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_test(image_file):\n","    input_image, real_image = load(image_file)\n","\n","    norm_input_image, norm_real_image = normalize2(input_image, real_image)\n","    norm_input_image,_,_ = tf.split(norm_input_image, num_or_size_splits=3, axis=-1)\n","    norm_real_image,_,_ = tf.split(norm_real_image, num_or_size_splits=3, axis=-1)\n","\n","    fi_real_image = tf_daugman_feature_extractor(norm_real_image)\n","    return norm_input_image, norm_real_image, fi_real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:06.245397Z","iopub.status.busy":"2023-11-18T10:46:06.245102Z","iopub.status.idle":"2023-11-18T10:46:10.456315Z","shell.execute_reply":"2023-11-18T10:46:10.455212Z","shell.execute_reply.started":"2023-11-18T10:46:06.245372Z"},"papermill":{"duration":0.869299,"end_time":"2023-10-11T09:27:21.466169","exception":false,"start_time":"2023-10-11T09:27:20.596870","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_dataset = tf.data.Dataset.list_files(str(DATASET_PATH / 'train/*.png'))\n","train_dataset = train_dataset.map(load_image_train,\n","                                  num_parallel_calls=tf.data.AUTOTUNE)\n","\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n","train_dataset = train_dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:10.458240Z","iopub.status.busy":"2023-11-18T10:46:10.457965Z","iopub.status.idle":"2023-11-18T10:46:11.132460Z","shell.execute_reply":"2023-11-18T10:46:11.131639Z","shell.execute_reply.started":"2023-11-18T10:46:10.458217Z"},"papermill":{"duration":0.08507,"end_time":"2023-10-11T09:27:21.558480","exception":false,"start_time":"2023-10-11T09:27:21.473410","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["validation_dataset = tf.data.Dataset.from_tensor_slices(validation_files)\n","validation_dataset = validation_dataset.map(load_image_validation)\n","validation_dataset = validation_dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:11.134111Z","iopub.status.busy":"2023-11-18T10:46:11.133755Z","iopub.status.idle":"2023-11-18T10:46:11.797611Z","shell.execute_reply":"2023-11-18T10:46:11.796765Z","shell.execute_reply.started":"2023-11-18T10:46:11.134078Z"},"papermill":{"duration":0.073422,"end_time":"2023-10-11T09:27:21.639212","exception":false,"start_time":"2023-10-11T09:27:21.565790","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["test_dataset = tf.data.Dataset.from_tensor_slices(test_files)\n","test_dataset = test_dataset.map(load_image_test,\n","                                    num_parallel_calls=tf.data.AUTOTUNE)\n","test_dataset = test_dataset.batch(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:11.805003Z","iopub.status.busy":"2023-11-18T10:46:11.804730Z","iopub.status.idle":"2023-11-18T10:46:11.814764Z","shell.execute_reply":"2023-11-18T10:46:11.814009Z","shell.execute_reply.started":"2023-11-18T10:46:11.804979Z"},"papermill":{"duration":0.017581,"end_time":"2023-10-11T09:27:43.912245","exception":false,"start_time":"2023-10-11T09:27:43.894664","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def downsample(filters, size, apply_batchnorm=True):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    \n","    result = tf.keras.Sequential()\n","    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n","\n","    if apply_batchnorm:\n","        result.add(tf.keras.layers.BatchNormalization())\n","\n","    result.add(tf.keras.layers.LeakyReLU())\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:11.825802Z","iopub.status.busy":"2023-11-18T10:46:11.825521Z","iopub.status.idle":"2023-11-18T10:46:11.837620Z","shell.execute_reply":"2023-11-18T10:46:11.836738Z","shell.execute_reply.started":"2023-11-18T10:46:11.825778Z"},"papermill":{"duration":0.016394,"end_time":"2023-10-11T09:27:43.959065","exception":false,"start_time":"2023-10-11T09:27:43.942671","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def upsample(filters, size, apply_dropout=False):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","\n","    result = tf.keras.Sequential()\n","    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n","                                    padding='same',\n","                                    kernel_initializer=initializer,\n","                                    use_bias=False))\n","\n","    result.add(tf.keras.layers.BatchNormalization())\n","\n","    if apply_dropout:\n","        result.add(tf.keras.layers.Dropout(0.5))\n","\n","    result.add(tf.keras.layers.ReLU())\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:11.848676Z","iopub.status.busy":"2023-11-18T10:46:11.848180Z","iopub.status.idle":"2023-11-18T10:46:11.858809Z","shell.execute_reply":"2023-11-18T10:46:11.857931Z","shell.execute_reply.started":"2023-11-18T10:46:11.848644Z"},"papermill":{"duration":0.017731,"end_time":"2023-10-11T09:27:44.006635","exception":false,"start_time":"2023-10-11T09:27:43.988904","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def Generator():\n","    inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS])\n","\n","    down_stack = [\n","        downsample(64, 4, apply_batchnorm=False), \n","        downsample(128, 4), \n","        downsample(256, 4),  \n","        downsample(512, 4), \n","      ]\n","\n","    up_stack = [\n","        upsample(512, 4, apply_dropout=True),  \n","        upsample(256, 4),\n","        upsample(128, 4), \n","        upsample(64, 4),\n","    ]\n","\n","\n","\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n","                                         strides=2,\n","                                         padding='same',\n","                                         kernel_initializer=initializer,\n","                                         activation='tanh') \n","\n","\n","    # --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- #\n","    x = inputs\n","\n","    # Downsampling through the model\n","    skips = []\n","    for down in down_stack:\n","        x = down(x)\n","        skips.append(x)\n","\n","    skips = reversed(skips[:-1])\n","\n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        x = tf.keras.layers.Concatenate()([x, skip])\n","\n","    x = last(x)\n","    \n","    return tf.keras.Model(inputs=inputs, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:11.860014Z","iopub.status.busy":"2023-11-18T10:46:11.859778Z","iopub.status.idle":"2023-11-18T10:46:12.464123Z","shell.execute_reply":"2023-11-18T10:46:12.463277Z","shell.execute_reply.started":"2023-11-18T10:46:11.859993Z"},"papermill":{"duration":0.729444,"end_time":"2023-10-11T09:27:44.742887","exception":false,"start_time":"2023-10-11T09:27:44.013443","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["generator = Generator()\n","#tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:12.465743Z","iopub.status.busy":"2023-11-18T10:46:12.465409Z","iopub.status.idle":"2023-11-18T10:46:17.273885Z","shell.execute_reply":"2023-11-18T10:46:17.272915Z","shell.execute_reply.started":"2023-11-18T10:46:12.465710Z"},"papermill":{"duration":5.788935,"end_time":"2023-10-11T09:27:50.541316","exception":false,"start_time":"2023-10-11T09:27:44.752381","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# -------- PRINT GENERATED IMAGES -------- #\n","\n","gen_output = generator(inpR[tf.newaxis, ...], training=False)\n","print(gen_output.shape)\n","#plt.imshow(gen_output[0, ...])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:17.275399Z","iopub.status.busy":"2023-11-18T10:46:17.275100Z","iopub.status.idle":"2023-11-18T10:46:18.252504Z","shell.execute_reply":"2023-11-18T10:46:18.250966Z","shell.execute_reply.started":"2023-11-18T10:46:17.275372Z"},"trusted":true},"outputs":[],"source":["def l1_loss(y_true, y_pred) : \n","    return tf.reduce_mean(tf.abs(y_true - y_pred))\n","\n","def l2_loss(y_true, y_pred) :\n","    return tf.reduce_mean(tf.square(y_true - y_pred))\n","\n","\n","def DiceLoss(y_true, y_pred, smooth=1e-6):\n","        \n","    # convert the tensor to one-hot for multi-class segmentation\n","    y_true = K.squeeze(y_true, 3)\n","    y_true = tf.cast(y_true, \"int32\")\n","    y_true = tf.one_hot(y_true, 4, axis=-1)\n","\n","    # cast to float32 datatype\n","    y_true = K.cast(y_true, 'float32')\n","    y_pred = K.cast(y_pred, 'float32')\n","    \n","    #flatten label and prediction tensors\n","    inputs = K.flatten(y_pred)\n","    targets = K.flatten(y_true)\n","\n","    intersection = K.sum(targets * inputs)\n","    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n","    return 1 - dice\n","\n","def IoULoss(y_true, y_pred, smooth=1e-6):\n","    # convert the tensor to one-hot for multi-class segmentation\n","    y_true = K.squeeze(y_true, 3)\n","    y_true = tf.cast(y_true, \"int32\")\n","    y_true = tf.one_hot(y_true, 4, axis=-1)\n","    \n","    # cast to float32 datatype\n","    y_true = K.cast(y_true, 'float32')\n","    y_pred = K.cast(y_pred, 'float32')\n","    \n","    #flatten label and prediction tensors\n","    inputs = K.flatten(y_pred)\n","    targets = K.flatten(y_true)\n","    \n","    intersection = K.sum(targets * inputs)\n","    total = K.sum(targets) + K.sum(inputs)\n","    union = total - intersection\n","    \n","    IoU = (intersection + smooth) / (union + smooth)\n","    return 1 - IoU\n","\n","scce_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=False,\n","    reduction='auto')\n","\n","# -------- FEATURE EXTRACTOR -------- #\n","\n","feature_extractor = tf.keras.models.load_model(FEATURE_EXTRACTOR_PATH)\n","#feature_extractor.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:18.254945Z","iopub.status.busy":"2023-11-18T10:46:18.254452Z","iopub.status.idle":"2023-11-18T10:46:18.261537Z","shell.execute_reply":"2023-11-18T10:46:18.260406Z","shell.execute_reply.started":"2023-11-18T10:46:18.254902Z"},"papermill":{"duration":0.028006,"end_time":"2023-10-11T09:27:53.571845","exception":false,"start_time":"2023-10-11T09:27:53.543839","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def generator_loss(gen_output, target, fi_target):\n","    fi_gen_output = feature_extractor(gen_output)\n","    \n","    pw_loss = l1_loss(target, gen_output)\n","    fe_loss = DiceLoss(fi_target, fi_gen_output)\n","    \n","    loss = pw_loss + (LAMBDA_F * fe_loss)\n","    \n","    return loss, pw_loss, fe_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:18.263032Z","iopub.status.busy":"2023-11-18T10:46:18.262780Z","iopub.status.idle":"2023-11-18T10:46:18.285618Z","shell.execute_reply":"2023-11-18T10:46:18.284773Z","shell.execute_reply.started":"2023-11-18T10:46:18.263009Z"},"papermill":{"duration":0.076301,"end_time":"2023-10-11T09:27:53.666767","exception":false,"start_time":"2023-10-11T09:27:53.590466","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def validation_step(generator, validation_ds) :\n","    val_error = []\n","    pw_error = []\n","    fe_error = []\n","    \n","    for input_image, target, fi_target in validation_ds:\n","        gen_output = generator(input_image, training=False)\n","        loss, pw_loss, fe_loss = generator_loss(gen_output, target, fi_target)\n","        val_error.append(loss)\n","        pw_error.append(pw_loss)\n","        fe_error.append(fe_loss)\n","        \n","    return np.mean(val_error), np.mean(pw_error), np.mean(fe_error)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:18.287255Z","iopub.status.busy":"2023-11-18T10:46:18.286938Z","iopub.status.idle":"2023-11-18T10:46:18.296215Z","shell.execute_reply":"2023-11-18T10:46:18.295315Z","shell.execute_reply.started":"2023-11-18T10:46:18.287228Z"},"papermill":{"duration":0.029447,"end_time":"2023-10-11T09:27:53.716274","exception":false,"start_time":"2023-10-11T09:27:53.686827","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def save_models(string, generator) :\n","    generator.save('models/' + string)\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:18.297619Z","iopub.status.busy":"2023-11-18T10:46:18.297319Z","iopub.status.idle":"2023-11-18T10:46:18.305934Z","shell.execute_reply":"2023-11-18T10:46:18.305168Z","shell.execute_reply.started":"2023-11-18T10:46:18.297594Z"},"trusted":true},"outputs":[],"source":["def create_mask(pred_mask):\n","    pred_mask = tf.argmax(pred_mask, axis=-1)\n","    pred_mask = pred_mask[..., tf.newaxis]\n","    return pred_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:18.307434Z","iopub.status.busy":"2023-11-18T10:46:18.307096Z","iopub.status.idle":"2023-11-18T10:46:18.318919Z","shell.execute_reply":"2023-11-18T10:46:18.318174Z","shell.execute_reply.started":"2023-11-18T10:46:18.307401Z"},"papermill":{"duration":0.032911,"end_time":"2023-10-11T09:27:53.769057","exception":false,"start_time":"2023-10-11T09:27:53.736146","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:18.321176Z","iopub.status.busy":"2023-11-18T10:46:18.320253Z","iopub.status.idle":"2023-11-18T10:46:18.327578Z","shell.execute_reply":"2023-11-18T10:46:18.326747Z","shell.execute_reply.started":"2023-11-18T10:46:18.321147Z"},"papermill":{"duration":0.030162,"end_time":"2023-10-11T09:27:53.818814","exception":false,"start_time":"2023-10-11T09:27:53.788652","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def generate_images(model, test_input, tar_input, tar_fi):\n","    prediction = model(test_input, training=False)\n","    fi_gen = feature_extractor(prediction)\n","    mask_prediction = create_mask(fi_gen)\n","    \n","    plt.figure(figsize=(15, 15))\n","\n","    display_list = [test_input[0], mask_prediction[0], tar_fi[0], prediction[0], tar_input[0]]\n","    title = ['Input Image', 'Prediction FI', 'Ground Truth FI', 'Predicted Image', 'Ground Truth']\n","\n","    for i in range(5):\n","        plt.subplot(1, 5, i+1)\n","        plt.title(title[i])\n","        # Getting the pixel values in the [0, 1] range to plot.\n","        plt.imshow(display_list[i])\n","        plt.axis('off')\n","    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:18.328953Z","iopub.status.busy":"2023-11-18T10:46:18.328658Z","iopub.status.idle":"2023-11-18T10:46:18.337434Z","shell.execute_reply":"2023-11-18T10:46:18.336530Z","shell.execute_reply.started":"2023-11-18T10:46:18.328929Z"},"papermill":{"duration":0.02992,"end_time":"2023-10-11T09:27:53.868153","exception":false,"start_time":"2023-10-11T09:27:53.838233","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def save_images(model, test_input, tar_input, tar_fi, step):\n","    prediction = model(test_input, training=False)\n","    fi_gen = feature_extractor(prediction)\n","    mask_prediction = create_mask(fi_gen)\n","    \n","    plt.figure(figsize=(15, 15))\n","\n","    display_list = [test_input[0], mask_prediction[0], tar_fi[0], prediction[0], tar_input[0]]\n","    title = ['Input Image', 'Prediction FI', 'Ground Truth FI', 'Predicted Image', 'Ground Truth']\n","\n","    for i in range(5):\n","        plt.subplot(1, 5, i+1)\n","        plt.title(title[i])\n","        # Getting the pixel values in the [0, 1] range to plot.\n","        plt.imshow(display_list[i])\n","        plt.axis('off')\n","        \n","    #plt.show()\n","    filename = 'image_' + str(step) + '.jpg'\n","    plt.savefig(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:18.338712Z","iopub.status.busy":"2023-11-18T10:46:18.338447Z","iopub.status.idle":"2023-11-18T10:46:18.354016Z","shell.execute_reply":"2023-11-18T10:46:18.353142Z","shell.execute_reply.started":"2023-11-18T10:46:18.338672Z"},"papermill":{"duration":0.034471,"end_time":"2023-10-11T09:27:53.972793","exception":false,"start_time":"2023-10-11T09:27:53.938322","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["summary_writer = tf.summary.create_file_writer(\n","    LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:46:18.360211Z","iopub.status.busy":"2023-11-18T10:46:18.359940Z","iopub.status.idle":"2023-11-18T10:46:18.367998Z","shell.execute_reply":"2023-11-18T10:46:18.367040Z","shell.execute_reply.started":"2023-11-18T10:46:18.360187Z"},"papermill":{"duration":0.030412,"end_time":"2023-10-11T09:27:54.023162","exception":false,"start_time":"2023-10-11T09:27:53.992750","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["@tf.function\n","def train_step(input_image, target, fi_target, step, pw_val_error, fe_val_error):\n","    with tf.GradientTape() as gen_tape :\n","        gen_output = generator(input_image, training=True)\n","\n","        gen_loss, pw_loss, fe_loss = generator_loss(gen_output, target, fi_target)\n","\n","    generator_gradients = gen_tape.gradient(gen_loss,\n","                                          generator.trainable_variables)\n","    \n","    generator_optimizer.apply_gradients(zip(generator_gradients,\n","                                          generator.trainable_variables))\n","\n","    with summary_writer.as_default():\n","        tf.summary.scalar('pw_loss', pw_loss, step=step//trainingset_size)\n","        tf.summary.scalar('fe_loss', fe_loss, step=step//trainingset_size)\n","        tf.summary.scalar('training_loss', gen_loss, step=step//trainingset_size)\n","        tf.summary.scalar('pw_validation_loss', pw_val_error, step=step//trainingset_size)\n","        tf.summary.scalar('fe_validation_loss', fe_val_error, step=step//trainingset_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:48:05.430757Z","iopub.status.busy":"2023-11-18T10:48:05.430059Z","iopub.status.idle":"2023-11-18T10:48:05.442535Z","shell.execute_reply":"2023-11-18T10:48:05.441584Z","shell.execute_reply.started":"2023-11-18T10:48:05.430722Z"},"papermill":{"duration":0.032289,"end_time":"2023-10-11T09:27:54.074499","exception":false,"start_time":"2023-10-11T09:27:54.042210","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def fit(train_ds, validation_ds, test_ds, steps):\n","    \n","    example_input, example_target, example_fi_target = next(iter(test_ds.take(1)))\n","    start = time.time()\n","    min_val_error = float(\"inf\")\n","    min_val_error =  float(\"inf\")\n","    fe_val_error = float(\"inf\")\n","    pw_val_error = float(\"inf\")\n","    count = 0\n","    count_stopping = 0\n","    \n","    for step, (input_image, target, fi_target) in train_ds.repeat().take(steps).enumerate():\n","        \n","        if (step) % trainingset_size == 0:\n","            #display.clear_output(wait=True)\n","\n","            if step != 0:\n","                print(f'Time taken for {trainingset_size} steps: {time.time()-start:.2f} sec\\n')\n","\n","            start = time.time()\n","\n","            generate_images(generator, example_input, example_target, example_fi_target)\n","            print(f\"Epoch: {step//trainingset_size}k\")\n","\n","        train_step(input_image, target, fi_target, step, pw_val_error, fe_val_error)\n","\n","        if ((count +1) % (trainingset_size/4)) == 0 : \n","            val_error, pw_val_error, fe_val_error = validation_step(generator, validation_ds)\n","            print(\"val_error : \", val_error, \"   at step : \", count)\n","            print(\"pw_error : \", pw_val_error, \"   at step : \", count)\n","            print(\"fe_error : \", fe_val_error, \"   at step : \", count)\n","\n","            if val_error < min_val_error :\n","                print(\"updating min_val_error..\")\n","                count_stopping = 0\n","                min_val_error = val_error\n","                filename = 'best_' + str(count + 1) + '.h5'\n","                \n","                save_images(generator, example_input, example_target,example_fi_target, count+1)\n","                save_models(filename, generator)\n","            else :\n","                count_stopping = count_stopping +1 \n","                \n","        if count_stopping > N_EPOCH_EARLY_STOPPING :\n","            break\n","                \n","        # Training step\n","        if (step+1) % int(trainingset_size * 0.05) == 0:\n","            print('.', end='', flush=True)\n","                           \n","        count = count +1 "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:48:08.467828Z","iopub.status.busy":"2023-11-18T10:48:08.467023Z"},"papermill":{"duration":42769.891539,"end_time":"2023-10-11T21:20:43.984902","exception":false,"start_time":"2023-10-11T09:27:54.093363","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["fit(train_dataset, validation_dataset, test_dataset, steps= NSTEPS)\n","save_models('last_model_.h5', generator)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4020755,"sourceId":6995058,"sourceType":"datasetVersion"},{"datasetId":3907314,"sourceId":6791975,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
