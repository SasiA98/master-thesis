{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-25T10:30:52.128527Z","iopub.status.busy":"2023-10-25T10:30:52.127475Z","iopub.status.idle":"2023-10-25T10:31:02.044847Z","shell.execute_reply":"2023-10-25T10:31:02.043664Z","shell.execute_reply.started":"2023-10-25T10:30:52.128483Z"},"papermill":{"duration":8.87465,"end_time":"2023-10-11T09:27:16.758128","exception":false,"start_time":"2023-10-11T09:27:07.883478","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from matplotlib import pyplot as plt\n","from keras.models import Model\n","from tensorflow.image import ssim\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n","import tensorflow_probability as tfp\n","import numpy as np\n","from IPython import display\n","import cv2\n","import tensorflow as tf\n","import os\n","import pathlib\n","import time\n","import datetime\n","import glob\n","import gc\n","\n","DATASET_PATH = 'task_3/dataset/processed_hk_norm_unenhanced_iris_dataset_64x240_png/'\n","\n","BATCH_SIZE = 4\n","\n","IMG_HEIGHT = 64\n","IMG_WIDTH = 240\n","# --------------------------------------------------------------------------------------------------------------- #\n","\n","# data disrtibution \n","\n","# 209 subjects \n","# 150 training   72%\n","# 30 validation  14%\n","# 29 testing     14%\n","\n","training_files = glob.glob(DATASET_PATH + 'train/*.png')\n","test_files = glob.glob(DATASET_PATH + 'test/*.png')\n","test_files.sort()\n","trainingset_size = len(training_files)\n","\n","validation_files = []\n","new_test_files = []\n","len_file = len(test_files[1])\n","\n","i=0\n","for file in test_files:\n","    sub = test_files[i][len_file-11:len_file-8]\n","    if int(sub) <= 180 :\n","        validation_files.append(file)\n","    else :\n","        new_test_files.append(file)\n","    i = i+1\n","\n","validationset_size = len(validation_files)\n","\n","test_files = new_test_files\n","testset_size = len(test_files)\n","\n","DATASET_PATH  = pathlib.Path(DATASET_PATH)\n","\n","# --------------------------------------------------------------------------------------------------------------- #\n","\n","# instead of epochs\n","EPOCHS = 80\n","\n","NSTEPS = trainingset_size * EPOCHS\n","\n","N_EPOCH_EARLY_STOPPING = 40 # 10 epochs * 4 \n","\n","INPUT_CHANNELS = 1\n","OUTPUT_CHANNELS = 4\n","\n","# buffer size is equal to training set size\n","BUFFER_SIZE = trainingset_size\n","\n","# log directory \n","LOG_DIR = \"logs/\" + '_nsteps_' + str(NSTEPS) + '_batchsize_' + str(BATCH_SIZE)  + '/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:02.047674Z","iopub.status.busy":"2023-10-25T10:31:02.047119Z","iopub.status.idle":"2023-10-25T10:31:02.053916Z","shell.execute_reply":"2023-10-25T10:31:02.052876Z","shell.execute_reply.started":"2023-10-25T10:31:02.047637Z"},"papermill":{"duration":0.016547,"end_time":"2023-10-11T09:27:16.781820","exception":false,"start_time":"2023-10-11T09:27:16.765273","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load(image_file):\n","    # Read and decode an image file to a uint8 tensor\n","    image = tf.io.read_file(image_file)\n","    image = tf.io.decode_png(image)\n","        \n","    # Split each image tensor into two tensors:\n","    # - one with a real building facade image\n","    # - one with an architecture label image \n","    w = tf.shape(image)[1]\n","    w = w // 2\n","\n","    input_image = image[:, :w, :]\n","    real_image = image[:, w:, :]\n","\n","    # Convert both images to float32 tensors\n","    input_image = tf.cast(input_image, tf.float32)\n","    real_image = tf.cast(real_image, tf.float32)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:02.056456Z","iopub.status.busy":"2023-10-25T10:31:02.055965Z","iopub.status.idle":"2023-10-25T10:31:02.080636Z","shell.execute_reply":"2023-10-25T10:31:02.079760Z","shell.execute_reply.started":"2023-10-25T10:31:02.056405Z"},"trusted":true},"outputs":[],"source":["def resize(input_image, real_image, height, width):\n","    input_image = tf.image.resize(input_image, [height, width],\n","                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    real_image = tf.image.resize(real_image, [height, width],\n","                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    \n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:02.083637Z","iopub.status.busy":"2023-10-25T10:31:02.083258Z","iopub.status.idle":"2023-10-25T10:31:02.089843Z","shell.execute_reply":"2023-10-25T10:31:02.088986Z","shell.execute_reply.started":"2023-10-25T10:31:02.083607Z"},"trusted":true},"outputs":[],"source":["def normalize(input_image, real_image):\n","    input_image = (input_image / 127.5) - 1\n","    real_image = (real_image / 127.5) - 1\n","\n","    return input_image, real_image\n","\n","def denormalize(input_image, real_image): # to [0, 255]\n","    input_image = (input_image + 1) * 127.5\n","    real_image = (real_image + 1) * 127.5\n","\n","    return real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:02.091129Z","iopub.status.busy":"2023-10-25T10:31:02.090858Z","iopub.status.idle":"2023-10-25T10:31:02.099905Z","shell.execute_reply":"2023-10-25T10:31:02.099030Z","shell.execute_reply.started":"2023-10-25T10:31:02.091107Z"},"papermill":{"duration":0.014905,"end_time":"2023-10-11T09:27:20.504740","exception":false,"start_time":"2023-10-11T09:27:20.489835","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# augmentation step \n","\n","def random_crop(input_image, real_image):\n","    stacked_image = tf.stack([input_image, real_image], axis=0)\n","    cropped_image = tf.image.random_crop(\n","        stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n","\n","    return cropped_image[0], cropped_image[1]\n","\n","@tf.function()\n","def random_jitter(input_image, real_image):\n","    # Resizing to 286x286\n","    jitter_offset = 30\n","    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT + jitter_offset, IMG_WIDTH + jitter_offset)\n","\n","    # Random cropping back to 256x256\n","    input_image, real_image = random_crop(input_image, real_image)\n","\n","    if tf.random.uniform(()) > 0.5:\n","        # Random mirroring\n","        input_image = tf.image.flip_left_right(input_image)\n","        real_image = tf.image.flip_left_right(real_image)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:02.115787Z","iopub.status.busy":"2023-10-25T10:31:02.115490Z","iopub.status.idle":"2023-10-25T10:31:02.147370Z","shell.execute_reply":"2023-10-25T10:31:02.146515Z","shell.execute_reply.started":"2023-10-25T10:31:02.115765Z"},"trusted":true},"outputs":[],"source":["# daugman feature extraction \n","\n","def tf_ProcessSingleChannel(channel):\n","    h = tf.histogram_fixed_width(channel, value_range=(0, 255), nbins=256)\n","\n","    h = tf.cast(h, tf.float32)\n","    pixel_values = tf.range(256, dtype=tf.float32)\n","    \n","    weighted_sum = tf.reduce_sum(pixel_values * h)\n","    total_pixels = tf.reduce_sum(h)\n","    mean_val = weighted_sum / total_pixels\n","\n","    # Compute variance and standard deviation\n","    variance = tf.reduce_sum(((pixel_values - mean_val) ** 2) * h) / total_pixels\n","    std_dev = tf.sqrt(variance)\n","\n","    # Compute Gaussian values\n","    gaussian_vals = (1 / (std_dev * tf.sqrt(2 * np.pi))) * tf.exp(-0.5 * ((pixel_values - mean_val) / std_dev) ** 2)\n","\n","    # Set threshold\n","    threshold = tf.reduce_max(gaussian_vals) * 0.1  # For example, 10% of the maximum\n","\n","    # Find values to eliminate\n","    to_eliminate = gaussian_vals < threshold\n","\n","    ProcessedChannel = tf.cast(tf.identity(channel), dtype=tf.float32)  # Create a copy\n","\n","    # Replace values below the threshold\n","    for i in range(len(to_eliminate)):\n","        if to_eliminate[i]:\n","            ProcessedChannel = tf.where(channel == i, mean_val + std_dev, ProcessedChannel)\n","\n","    return ProcessedChannel\n","\n","def tf_GaussHistCut(image):\n","    channels = 1\n","    if len(image.shape) > 2:\n","        _, _, channels = image.shape\n","\n","    if channels == 3:  # RGB image\n","        CorrectedImage = tf.zeros_like(image, dtype=tf.uint8)\n","\n","        for ch in range(channels):\n","            CorrectedImage[:, :, ch] = tf_ProcessSingleChannel(image[:, :, ch])\n","    \n","    else:  # Grayscale image\n","        CorrectedImage = tf_ProcessSingleChannel(image)\n","\n","    return CorrectedImage\n","\n","def tf_rescale(data):\n","    data_min = tf.reduce_min(data)\n","    data_max = tf.reduce_max(data)\n","    return (data - data_min) / (data_max - data_min)\n","\n","def tf_mad_normalize(channel):\n","    mad = tfp.stats.percentile(tf.abs(channel - tfp.stats.percentile(channel, 50)), 50)\n","    is_zero_mad = tf.equal(mad, 0)\n","    channel = tf.where(is_zero_mad, tf.zeros_like(channel), (channel - tfp.stats.percentile(channel, 50)) / mad)\n","    return tf_rescale(channel)\n","\n","def tf_daugman_normalization(image) : #(image):\n","\n","    AR, AG, AB = tf.split(image, num_or_size_splits=3, axis=-1)\n","\n","    # Apply GaussHistCut\n","    AR = tf_GaussHistCut(tf.cast(AR, dtype=tf.int32)) #uint8 non Ã¨ supportato da hist\n","    #AG = tf_GaussHistCut(AG)\n","    #AB = tf_GaussHistCut(AB)\n","\n","    AR = tf_mad_normalize(AR)\n","    #AG = tf_mad_normalize(AG)\n","    #AB = tf_mad_normalize(AB)\n","\n","    # Replace NaN and Inf values with 0\n","    AR = tf.where(tf.math.is_nan(AR) | tf.math.is_inf(AR), tf.zeros_like(AR), AR)\n","    #AG = tf.where(tf.math.is_nan(AG) | tf.math.is_inf(AG), tf.zeros_like(AG), AG)\n","    #AB = tf.where(tf.math.is_nan(AB) | tf.math.is_inf(AB), tf.zeros_like(AB), AB)\n","\n","    # Create the normalized image\n","    #norm_image = tf.concat([AR, AG, AB], axis=-1)\n","\n","    return AR #return norm_image\n","    \n","def tf_gaborconvolve(im, nscale, minWaveLength, mult, sigmaOnf):\n","    rows = IMG_HEIGHT #im.shape[0]\n","    cols = IMG_WIDTH #im.shape[1]\n","    \n","    filtersum = tf.zeros(cols, dtype=tf.float32)\n","    EO = [None] * nscale\n","    \n","    ndata = cols\n","\n","    logGabor = tf.zeros(ndata, dtype=tf.float32)\n","    result = tf.zeros([rows, ndata], dtype=tf.complex128)\n","    \n","    radius = tf.range(0, ndata // 2 + 1, dtype=tf.float64) / (ndata // 2) / 2  # Frequency values 0 - 0.5\n","    zerovalue = tf.cast(tf.constant([1.0]), dtype=tf.float64)\n","    radius = tf.tensor_scatter_nd_update(radius, tf.constant([[0]]), zerovalue)\n","    \n","    wavelength = minWaveLength  # Initialize filter wavelength\n","    \n","    for s in range(nscale):\n","        # Construct the filter - first calculate the radial filter component\n","        fo = 1.0 / wavelength  # Centre frequency of filter\n","        # corresponding to fo\n","        \n","        sum = tf.exp( tf.cast( - tf.pow((tf.math.log(radius/fo)), 2), dtype=tf.float32) / (2 * tf.pow(tf.math.log(sigmaOnf), 2)))\n","\n","\n","        indexes = tf.expand_dims(tf.range(0, sum.shape[0]), axis=1)\n","\n","        logGabor = tf.tensor_scatter_nd_update(logGabor, indexes, sum)\n","        logGabor = tf.tensor_scatter_nd_update(logGabor, tf.constant([[0]]), tf.constant([0.0]))\n","        \n","        filter = logGabor\n","        filtersum = filtersum + filter\n","        \n","        for r in range(rows):\n","            signal = im[r, 0:ndata]\n","            imagefft = tf.signal.fft(tf.cast(signal, dtype=tf.complex128))\n","            filter = tf.cast(filter, dtype=tf.complex128)\n","            result = tf.tensor_scatter_nd_add(result, [tf.constant([r])], [tf.signal.ifft(imagefft * filter)])\n","        \n","        EO[s] = result\n","        wavelength *= mult  # Finally calculate the wavelength of the next filter\n","    \n","    filtersum = tf.signal.fftshift(filtersum)\n","    \n","    return EO, filtersum\n","\n","def tf_encode(polar_array, nscales, minWaveLength, mult, sigmaOnf):\n","    # Convoluzione della regione normalizzata con filtri di Gabor\n","    E0, _ = tf_gaborconvolve(polar_array, nscales, minWaveLength, mult, sigmaOnf)\n","    \n","    H = tf.zeros(E0[0].shape)\n","    for k in range(1, nscales + 1):\n","        E1 = E0[k - 1]\n","\n","        cond_0 = tf.math.logical_and(tf.math.real(E1) <= 0, tf.math.imag(E1) <= 0)\n","        cond_1 = tf.math.logical_and(tf.math.real(E1) <= 0, tf.math.imag(E1) > 0)\n","        cond_2 = tf.math.logical_and(tf.math.real(E1) > 0, tf.math.imag(E1) <= 0)\n","        cond_3 = tf.math.logical_and(tf.math.real(E1) > 0, tf.math.imag(E1) > 0)\n","\n","        H=tf.where(cond_0,0.0,H)\n","        H=tf.where(cond_1,1.0,H)\n","        H=tf.where(cond_2,2.0,H)\n","        H=tf.where(cond_3,3.0,H)\n","\n","    return H\n","\n","def tf_GaborBitStreamSTACKED(AR): #polarImage):\n","\n","    #AR, AG, AB = tf.split(polarImage, num_or_size_splits=3, axis=-1)\n","\n","    nscales = 1\n","    minWaveLength = 24\n","    mult = 1\n","    sigmaOnf = 0.5\n","\n","    TR = tf_encode(tf.squeeze(AR), nscales, minWaveLength, mult, sigmaOnf)\n","    #TG = tf_encode(tf.squeeze(AG), nscales, minWaveLength, mult, sigmaOnf)\n","    #TB = tf_encode(tf.squeeze(AB), nscales, minWaveLength, mult, sigmaOnf)\n","\n","    TR = tf.cast(TR, dtype=tf.uint8)\n","\n","    return tf.expand_dims(TR, axis=2) #return tf.concat([tf.expand_dims(TR, axis=2) , tf.expand_dims(TG, axis=2), tf.expand_dims(TB, axis=2)], axis=-1)\n","\n","def tf_daugman_feature_extractor(inp):\n","    return tf_GaborBitStreamSTACKED(inp)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:02.149031Z","iopub.status.busy":"2023-10-25T10:31:02.148583Z","iopub.status.idle":"2023-10-25T10:31:07.888073Z","shell.execute_reply":"2023-10-25T10:31:07.887022Z","shell.execute_reply.started":"2023-10-25T10:31:02.149003Z"},"trusted":true},"outputs":[],"source":["# printing input image - feature image\n","\n","inp,tar = load(training_files[1])\n","print(training_files[0])\n","norm_inp = tf_daugman_normalization(inp)\n","norm_tar = tf_daugman_normalization(tar)\n","\n","fi_inp= tf_daugman_feature_extractor(norm_inp)\n","fi_tar = tf_daugman_feature_extractor(norm_tar)\n","\n","display_list = [inp/255.0 , norm_inp, fi_tar]\n","title = ['Input Image', 'Norm_Input 1D', 'Feature Image']\n","plt.figure(figsize=(15, 15))\n","\n","for i in range(3):\n","    plt.subplot(1, 3, i+1)\n","    plt.title(title[i])\n","    plt.imshow(display_list[i])\n","    #plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:07.889627Z","iopub.status.busy":"2023-10-25T10:31:07.889333Z","iopub.status.idle":"2023-10-25T10:31:07.895444Z","shell.execute_reply":"2023-10-25T10:31:07.894353Z","shell.execute_reply.started":"2023-10-25T10:31:07.889602Z"},"papermill":{"duration":0.014732,"end_time":"2023-10-11T09:27:20.547759","exception":false,"start_time":"2023-10-11T09:27:20.533027","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_train(image_file):\n","    input_image, real_image = load(image_file)\n","\n","    input_image = tf_daugman_normalization(input_image)\n","\n","    real_image = tf_daugman_normalization(real_image)\n","    real_image = tf_daugman_feature_extractor(real_image)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:07.900571Z","iopub.status.busy":"2023-10-25T10:31:07.900208Z","iopub.status.idle":"2023-10-25T10:31:07.906797Z","shell.execute_reply":"2023-10-25T10:31:07.905980Z","shell.execute_reply.started":"2023-10-25T10:31:07.900538Z"},"papermill":{"duration":0.01435,"end_time":"2023-10-11T09:27:20.569005","exception":false,"start_time":"2023-10-11T09:27:20.554655","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_validation(image_file):\n","    input_image, real_image = load(image_file)\n","\n","    input_image = tf_daugman_normalization(input_image)\n","\n","    real_image = tf_daugman_normalization(real_image)\n","    real_image = tf_daugman_feature_extractor(real_image)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:07.908061Z","iopub.status.busy":"2023-10-25T10:31:07.907776Z","iopub.status.idle":"2023-10-25T10:31:07.917714Z","shell.execute_reply":"2023-10-25T10:31:07.916843Z","shell.execute_reply.started":"2023-10-25T10:31:07.908033Z"},"papermill":{"duration":0.014275,"end_time":"2023-10-11T09:27:20.590115","exception":false,"start_time":"2023-10-11T09:27:20.575840","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_image_test(image_file):\n","    input_image, real_image = load(image_file)\n","\n","    input_image = tf_daugman_normalization(input_image)\n","\n","    real_image = tf_daugman_normalization(real_image)\n","    real_image = tf_daugman_feature_extractor(real_image)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:07.918974Z","iopub.status.busy":"2023-10-25T10:31:07.918657Z","iopub.status.idle":"2023-10-25T10:31:18.351204Z","shell.execute_reply":"2023-10-25T10:31:18.350343Z","shell.execute_reply.started":"2023-10-25T10:31:07.918943Z"},"papermill":{"duration":0.869299,"end_time":"2023-10-11T09:27:21.466169","exception":false,"start_time":"2023-10-11T09:27:20.596870","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_dataset = tf.data.Dataset.list_files(str(DATASET_PATH / 'train/*.png'))\n","train_dataset = train_dataset.map(load_image_train,\n","                                  num_parallel_calls=tf.data.AUTOTUNE)\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n","train_dataset = train_dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T10:31:18.352671Z","iopub.status.busy":"2023-10-25T10:31:18.352379Z"},"papermill":{"duration":0.08507,"end_time":"2023-10-11T09:27:21.558480","exception":false,"start_time":"2023-10-11T09:27:21.473410","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["validation_dataset = tf.data.Dataset.from_tensor_slices(validation_files)\n","validation_dataset = validation_dataset.map(load_image_validation)\n","validation_dataset = validation_dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.073422,"end_time":"2023-10-11T09:27:21.639212","exception":false,"start_time":"2023-10-11T09:27:21.565790","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["test_dataset = tf.data.Dataset.from_tensor_slices(test_files)\n","test_dataset = test_dataset.map(load_image_test,\n","                                    num_parallel_calls=tf.data.AUTOTUNE)\n","test_dataset = test_dataset.batch(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.017581,"end_time":"2023-10-11T09:27:43.912245","exception":false,"start_time":"2023-10-11T09:27:43.894664","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def downsample(filters, size, apply_batchnorm=True):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    \n","    result = tf.keras.Sequential()\n","    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n","\n","    if apply_batchnorm:\n","        result.add(tf.keras.layers.BatchNormalization())\n","\n","    result.add(tf.keras.layers.LeakyReLU())\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.016394,"end_time":"2023-10-11T09:27:43.959065","exception":false,"start_time":"2023-10-11T09:27:43.942671","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def upsample(filters, size, apply_dropout=False):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","\n","    result = tf.keras.Sequential()\n","    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n","                                    padding='same',\n","                                    kernel_initializer=initializer,\n","                                    use_bias=False))\n","\n","    result.add(tf.keras.layers.BatchNormalization())\n","\n","    if apply_dropout:\n","        result.add(tf.keras.layers.Dropout(0.5))\n","\n","    result.add(tf.keras.layers.ReLU())\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.017731,"end_time":"2023-10-11T09:27:44.006635","exception":false,"start_time":"2023-10-11T09:27:43.988904","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def Generator():\n","    inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS])\n","\n","    down_stack = [\n","        downsample(64, 4, apply_batchnorm=False),  \n","        downsample(128, 4), \n","        downsample(256, 4),  \n","        downsample(512, 4),  \n","      ]\n","\n","    up_stack = [\n","        upsample(512, 4, apply_dropout=True),  \n","        upsample(256, 4),  \n","        upsample(128, 4),\n","        upsample(64, 4), \n","    ]\n","\n","\n","\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n","                                         strides=2,\n","                                         padding='same',\n","                                         kernel_initializer=initializer,\n","                                         activation='softmax') \n","\n","\n","    # --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- #\n","    x = inputs\n","\n","    # Downsampling through the model\n","    skips = []\n","    for down in down_stack:\n","        x = down(x)\n","        skips.append(x)\n","\n","    skips = reversed(skips[:-1])\n","\n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        x = tf.keras.layers.Concatenate()([x, skip])\n","\n","    x = last(x)\n","    \n","    return tf.keras.Model(inputs=inputs, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.729444,"end_time":"2023-10-11T09:27:44.742887","exception":false,"start_time":"2023-10-11T09:27:44.013443","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["generator = Generator()\n","#tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":5.788935,"end_time":"2023-10-11T09:27:50.541316","exception":false,"start_time":"2023-10-11T09:27:44.752381","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# -------- PRINT GENERATED IMAGES -------- #\n","\n","gen_output = generator(norm_inp[tf.newaxis, ...], training=False)\n","#print(gen_output.shape)\n","#plt.imshow(gen_output[0, ...])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def DiceLoss(y_true, y_pred, smooth=1e-6):\n","    # convert the tensor to one-hot for multi-class segmentation\n","    y_true = K.squeeze(y_true, 3)\n","    y_true = tf.cast(y_true, \"int32\")\n","    y_true = tf.one_hot(y_true, 4, axis=-1)\n","    \n","    # cast to float32 datatype\n","    y_true = K.cast(y_true, 'float32')\n","    y_pred = K.cast(y_pred, 'float32')\n","    \n","    #flatten label and prediction tensors\n","    inputs = K.flatten(y_pred)\n","    targets = K.flatten(y_true)\n","\n","    intersection = K.sum(targets * inputs)\n","    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n","    return 1 - dice\n","\n","\n","#Tensorflow / Keras \n","def IoULoss(y_true, y_pred, smooth=1e-6):\n","    # convert the tensor to one-hot for multi-class segmentation\n","    y_true = K.squeeze(y_true, 3)\n","    y_true = tf.cast(y_true, \"int32\")\n","    y_true = tf.one_hot(y_true, 4, axis=-1)\n","    \n","    # cast to float32 datatype\n","    y_true = K.cast(y_true, 'float32')\n","    y_pred = K.cast(y_pred, 'float32')\n","    \n","    #flatten label and prediction tensors\n","    inputs = K.flatten(y_pred)\n","    targets = K.flatten(y_true)\n","    \n","    intersection = K.sum(targets * inputs)\n","    total = K.sum(targets) + K.sum(inputs)\n","    union = total - intersection\n","    \n","    IoU = (intersection + smooth) / (union + smooth)\n","    return 1 - IoU\n","\n","scce_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=False,\n","    reduction='auto')"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.028006,"end_time":"2023-10-11T09:27:53.571845","exception":false,"start_time":"2023-10-11T09:27:53.543839","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def generator_loss(gen_output, target):\n","    return IoULoss(target, gen_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_mask(pred_mask):\n","    pred_mask = tf.argmax(pred_mask, axis=-1)\n","    pred_mask = pred_mask[..., tf.newaxis]\n","    return pred_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.076301,"end_time":"2023-10-11T09:27:53.666767","exception":false,"start_time":"2023-10-11T09:27:53.590466","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def validation_step(generator, validation_ds) :\n","    val_error = []\n","    for input_image, target in validation_ds:\n","        gen_output = generator(input_image, training=False)\n","        loss = generator_loss(gen_output, target)\n","        val_error.append(loss)\n","        \n","    return np.mean(val_error)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.029447,"end_time":"2023-10-11T09:27:53.716274","exception":false,"start_time":"2023-10-11T09:27:53.686827","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def save_models(string, generator) :\n","    generator.save('models/' + string)\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.032911,"end_time":"2023-10-11T09:27:53.769057","exception":false,"start_time":"2023-10-11T09:27:53.736146","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["#generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","generator_optimizer = tf.keras.optimizers.SGD()"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.030162,"end_time":"2023-10-11T09:27:53.818814","exception":false,"start_time":"2023-10-11T09:27:53.788652","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def generate_images(model, test_input, tar):\n","    prediction = model(test_input, training=False)\n","    mask_prediction = create_mask(prediction)\n","\n","    plt.figure(figsize=(15, 15))\n","\n","    display_list = [test_input[0], tar[0], mask_prediction[0]]\n","    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n","\n","    for i in range(3):\n","        plt.subplot(1, 3, i+1)\n","        plt.title(title[i])\n","        # Getting the pixel values in the [0, 1] range to plot.\n","        plt.imshow(display_list[i])\n","        plt.axis('off')\n","    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.02992,"end_time":"2023-10-11T09:27:53.868153","exception":false,"start_time":"2023-10-11T09:27:53.838233","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def save_images(model, test_input, tar, step):\n","    prediction = model(test_input)#, training=True)\n","    mask_prediction = create_mask(prediction)\n","    plt.figure(figsize=(15, 15))\n","\n","    display_list = [test_input[0], tar[0], mask_prediction[0]]\n","    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n","\n","    for i in range(3):\n","        plt.subplot(1, 3, i+1)\n","        plt.title(title[i])\n","        # Getting the pixel values in the [0, 1] range to plot.\n","        plt.imshow(display_list[i])\n","        plt.axis('off')\n","    #plt.show()\n","    filename = 'image_' + str(step) + '.jpg'\n","    plt.savefig(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.034471,"end_time":"2023-10-11T09:27:53.972793","exception":false,"start_time":"2023-10-11T09:27:53.938322","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["summary_writer = tf.summary.create_file_writer(\n","    LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.030412,"end_time":"2023-10-11T09:27:54.023162","exception":false,"start_time":"2023-10-11T09:27:53.992750","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["@tf.function\n","def train_step(input_image, target, step, pw_val_error):\n","    with tf.GradientTape() as gen_tape :\n","        gen_output = generator(input_image, training=True)\n","\n","        gen_loss = generator_loss(gen_output, target)\n","\n","    generator_gradients = gen_tape.gradient(gen_loss,\n","                                          generator.trainable_variables)\n","    \n","    generator_optimizer.apply_gradients(zip(generator_gradients,\n","                                          generator.trainable_variables))\n","\n","    with summary_writer.as_default():\n","        tf.summary.scalar(\"loss\", gen_loss, step=step//trainingset_size)\n","        tf.summary.scalar('pw_val_error', pw_val_error, step=step//trainingset_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.032289,"end_time":"2023-10-11T09:27:54.074499","exception":false,"start_time":"2023-10-11T09:27:54.042210","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def fit(train_ds, validation_ds, test_ds, steps):\n","    \n","    example_input, example_target = next(iter(test_ds.take(1)))\n","    start = time.time()\n","    min_val_error = float(\"inf\")\n","    pw_val_error = float(\"inf\")\n","    count = 0\n","    count_stopping = 0\n","\n","    for step, (input_image, target) in train_ds.repeat().take(steps).enumerate():\n","        \n","        if (step) % trainingset_size == 0:\n","            display.clear_output(wait=True)\n","\n","            if step != 0:\n","                print(f'Time taken for {trainingset_size} steps: {time.time()-start:.2f} sec\\n')\n","\n","            start = time.time()\n","\n","            generate_images(generator, example_input, example_target)\n","            print(f\"Step: {step//trainingset_size}k\")\n","\n","        train_step(input_image, target, step, pw_val_error)\n","\n","        if ((count +1) % trainingset_size) == 0 : \n","            pw_val_error = validation_step(generator, validation_ds)\n","            print(\"pw_error : \", pw_val_error, \"   at step : \", count)\n","            \n","            if pw_val_error < min_val_error :\n","                print(\"updating min_val_error..\")\n","                count_stopping = 0\n","                min_val_error = pw_val_error\n","                filename = 'best_' + str(count + 1) + '.h5'\n","\n","                save_images(generator, example_input, example_target, count+1)\n","                save_models(filename, generator)\n","            else :\n","                count_stopping = count_stopping +1 \n","\n","        \n","        # Training step\n","        if (step+1) % int(trainingset_size * 0.05) == 0:\n","            print('.', end='', flush=True)\n","                           \n","        count = count +1 "]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":42769.891539,"end_time":"2023-10-11T21:20:43.984902","exception":false,"start_time":"2023-10-11T09:27:54.093363","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["fit(train_dataset, validation_dataset, test_dataset, steps= NSTEPS)\n","save_models('last_model_.h5', generator)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"papermill":{"default_parameters":{},"duration":42822.800413,"end_time":"2023-10-11T21:20:47.581977","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-10-11T09:27:04.781564","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}
