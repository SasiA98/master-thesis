{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869645e9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:19.891867Z",
     "iopub.status.busy": "2023-10-16T09:42:19.891563Z",
     "iopub.status.idle": "2023-10-16T09:42:28.785268Z",
     "shell.execute_reply": "2023-10-16T09:42:28.784355Z"
    },
    "papermill": {
     "duration": 8.904104,
     "end_time": "2023-10-16T09:42:28.787391",
     "exception": false,
     "start_time": "2023-10-16T09:42:19.883287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from tensorflow.image import ssim\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from IPython import display\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "import datetime\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "\n",
    "DATASET_PATH = 'task_3/dataset/processed_hk_norm_unenhanced_iris_dataset_64x240_png/'\n",
    "\n",
    "# The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Each image is 256x256 in size\n",
    "IMG_WIDTH = 240\n",
    "IMG_HEIGHT = 64\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "# data disrtibution \n",
    "\n",
    "# 209 subjects \n",
    "# 150 training   72%\n",
    "# 30 validation  14%\n",
    "# 29 testing     14%\n",
    "\n",
    "training_files = glob.glob(DATASET_PATH + 'train/*.png')\n",
    "test_files = glob.glob(DATASET_PATH + 'test/*.png')\n",
    "test_files.sort()\n",
    "trainingset_size = len(training_files)\n",
    "\n",
    "validation_files = []\n",
    "new_test_files = []\n",
    "len_file = len(test_files[1])\n",
    "\n",
    "i=0\n",
    "for file in test_files:\n",
    "    sub = test_files[i][len_file-11:len_file-8]\n",
    "    if int(sub) <= 180 :\n",
    "        validation_files.append(file)\n",
    "    else :\n",
    "        new_test_files.append(file)\n",
    "    i = i+1\n",
    "\n",
    "\n",
    "validationset_size = len(validation_files)\n",
    "\n",
    "test_files = new_test_files\n",
    "testset_size = len(test_files)\n",
    "\n",
    "DATASET_PATH  = pathlib.Path(DATASET_PATH)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "# instead of epochs\n",
    "EPOCHS = 5\n",
    "N_EPOCHS_VAL_STEP = 0\n",
    "\n",
    "NSTEPS = trainingset_size * EPOCHS\n",
    "\n",
    "# dataset is made of RBG images \n",
    "INPUT_CHANNELS = 1\n",
    "OUTPUT_CHANNELS = 4\n",
    "\n",
    "# generator loss function hyperparameter \n",
    "LAMBDA_P = 1\n",
    "\n",
    "# buffer size is equal to training set size\n",
    "BUFFER_SIZE = trainingset_size\n",
    "\n",
    "# model filename refears to steps number and batch size\n",
    "MODEL_FILENAME = '_nsteps_' + str(NSTEPS) + '_batchsize_' + str(BATCH_SIZE) + '.h5'\n",
    "\n",
    "# log directory \n",
    "LOG_DIR = \"logs/\" + '_nsteps_' + str(NSTEPS) + '_batchsize_' + str(BATCH_SIZE)  + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4143734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:28.801286Z",
     "iopub.status.busy": "2023-10-16T09:42:28.800823Z",
     "iopub.status.idle": "2023-10-16T09:42:28.806092Z",
     "shell.execute_reply": "2023-10-16T09:42:28.805217Z"
    },
    "papermill": {
     "duration": 0.013832,
     "end_time": "2023-10-16T09:42:28.807772",
     "exception": false,
     "start_time": "2023-10-16T09:42:28.793940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load(image_file):\n",
    "    # Read and decode an image file to a uint8 tensor\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.io.decode_png(image)\n",
    "\n",
    "\n",
    "    # Split each image tensor into two tensors:\n",
    "    # - one with a real building facade image\n",
    "    # - one with an architecture label image \n",
    "    w = tf.shape(image)[1]\n",
    "    w = w // 2\n",
    "\n",
    "    input_image = image[:, :w, :]\n",
    "    real_image = image[:, w:, :]\n",
    "\n",
    "    # Convert both images to float32 tensors\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b1a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:28.824208Z",
     "iopub.status.busy": "2023-10-16T09:42:28.823973Z",
     "iopub.status.idle": "2023-10-16T09:42:28.828350Z",
     "shell.execute_reply": "2023-10-16T09:42:28.827516Z"
    },
    "papermill": {
     "duration": 0.016293,
     "end_time": "2023-10-16T09:42:28.830021",
     "exception": false,
     "start_time": "2023-10-16T09:42:28.813728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize(input_image, real_image, height, width):\n",
    "    input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [height, width],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74fc37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:28.842975Z",
     "iopub.status.busy": "2023-10-16T09:42:28.842747Z",
     "iopub.status.idle": "2023-10-16T09:42:28.846705Z",
     "shell.execute_reply": "2023-10-16T09:42:28.845855Z"
    },
    "papermill": {
     "duration": 0.01237,
     "end_time": "2023-10-16T09:42:28.848322",
     "exception": false,
     "start_time": "2023-10-16T09:42:28.835952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(input_image, real_image):\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    real_image = (real_image / 127.5) - 1\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "def denormalize(input_image, real_image): # to [0, 255]\n",
    "    input_image = (input_image + 1) * 127.5\n",
    "    real_image = (real_image + 1) * 127.5\n",
    "\n",
    "    return real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation step \n",
    "\n",
    "def random_crop(input_image, real_image):\n",
    "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
    "    cropped_image = tf.image.random_crop(\n",
    "        stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image[0], cropped_image[1]\n",
    "\n",
    "@tf.function()\n",
    "def random_jitter(input_image, real_image):\n",
    "    # Resizing to 286x286\n",
    "    jitter_offset = 30\n",
    "    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT + jitter_offset, IMG_WIDTH + jitter_offset)\n",
    "\n",
    "    # Random cropping back to 256x256\n",
    "    input_image, real_image = random_crop(input_image, real_image)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        # Random mirroring\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        real_image = tf.image.flip_left_right(real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e13355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daugman feature extraction \n",
    "\n",
    "def tf_ProcessSingleChannel(channel):\n",
    "    h = tf.histogram_fixed_width(channel, value_range=(0, 255), nbins=256)\n",
    "\n",
    "    h = tf.cast(h, tf.float32)\n",
    "    pixel_values = tf.range(256, dtype=tf.float32)\n",
    "    \n",
    "    weighted_sum = tf.reduce_sum(pixel_values * h)\n",
    "    total_pixels = tf.reduce_sum(h)\n",
    "    mean_val = weighted_sum / total_pixels\n",
    "\n",
    "    # Compute variance and standard deviation\n",
    "    variance = tf.reduce_sum(((pixel_values - mean_val) ** 2) * h) / total_pixels\n",
    "    std_dev = tf.sqrt(variance)\n",
    "\n",
    "    # Compute Gaussian values\n",
    "    gaussian_vals = (1 / (std_dev * tf.sqrt(2 * np.pi))) * tf.exp(-0.5 * ((pixel_values - mean_val) / std_dev) ** 2)\n",
    "\n",
    "    # Set threshold\n",
    "    threshold = tf.reduce_max(gaussian_vals) * 0.1  # For example, 10% of the maximum\n",
    "\n",
    "    # Find values to eliminate\n",
    "    to_eliminate = gaussian_vals < threshold\n",
    "\n",
    "    ProcessedChannel = tf.cast(tf.identity(channel), dtype=tf.float32)  # Create a copy\n",
    "\n",
    "    # Replace values below the threshold\n",
    "    for i in range(len(to_eliminate)):\n",
    "        if to_eliminate[i]:\n",
    "            ProcessedChannel = tf.where(channel == i, mean_val + std_dev, ProcessedChannel)\n",
    "\n",
    "    return ProcessedChannel\n",
    "\n",
    "def tf_GaussHistCut(image):\n",
    "    channels = 1\n",
    "    if len(image.shape) > 2:\n",
    "        _, _, channels = image.shape\n",
    "\n",
    "    if channels == 3:  # RGB image\n",
    "        CorrectedImage = tf.zeros_like(image, dtype=tf.uint8)\n",
    "\n",
    "        for ch in range(channels):\n",
    "            CorrectedImage[:, :, ch] = tf_ProcessSingleChannel(image[:, :, ch])\n",
    "    \n",
    "    else:  # Grayscale image\n",
    "        CorrectedImage = tf_ProcessSingleChannel(image)\n",
    "\n",
    "    return CorrectedImage\n",
    "\n",
    "def tf_rescale(data):\n",
    "    data_min = tf.reduce_min(data)\n",
    "    data_max = tf.reduce_max(data)\n",
    "    return (data - data_min) / (data_max - data_min)\n",
    "\n",
    "def tf_mad_normalize(channel):\n",
    "    mad = tfp.stats.percentile(tf.abs(channel - tfp.stats.percentile(channel, 50)), 50)\n",
    "    is_zero_mad = tf.equal(mad, 0)\n",
    "    channel = tf.where(is_zero_mad, tf.zeros_like(channel), (channel - tfp.stats.percentile(channel, 50)) / mad)\n",
    "    return tf_rescale(channel)\n",
    "\n",
    "def tf_daugman_normalization(image) : #(image):\n",
    "\n",
    "    AR, AG, AB = tf.split(image, num_or_size_splits=3, axis=-1)\n",
    "\n",
    "    # Apply GaussHistCut\n",
    "    AR = tf_GaussHistCut(tf.cast(AR, dtype=tf.int32)) #uint8 non è supportato da hist\n",
    "    #AG = tf_GaussHistCut(AG)\n",
    "    #AB = tf_GaussHistCut(AB)\n",
    "\n",
    "    AR = tf_mad_normalize(AR)\n",
    "    #AG = tf_mad_normalize(AG)\n",
    "    #AB = tf_mad_normalize(AB)\n",
    "\n",
    "    # Replace NaN and Inf values with 0\n",
    "    AR = tf.where(tf.math.is_nan(AR) | tf.math.is_inf(AR), tf.zeros_like(AR), AR)\n",
    "    #AG = tf.where(tf.math.is_nan(AG) | tf.math.is_inf(AG), tf.zeros_like(AG), AG)\n",
    "    #AB = tf.where(tf.math.is_nan(AB) | tf.math.is_inf(AB), tf.zeros_like(AB), AB)\n",
    "\n",
    "    # Create the normalized image\n",
    "    #norm_image = tf.concat([AR, AG, AB], axis=-1)\n",
    "\n",
    "    return AR #return norm_image\n",
    "    \n",
    "def tf_gaborconvolve(im, nscale, minWaveLength, mult, sigmaOnf):\n",
    "    rows = IMG_HEIGHT #im.shape[0]\n",
    "    cols = IMG_WIDTH #im.shape[1]\n",
    "    \n",
    "    filtersum = tf.zeros(cols, dtype=tf.float32)\n",
    "    EO = [None] * nscale\n",
    "    \n",
    "    ndata = cols\n",
    "\n",
    "    logGabor = tf.zeros(ndata, dtype=tf.float32)\n",
    "    result = tf.zeros([rows, ndata], dtype=tf.complex128)\n",
    "    \n",
    "    radius = tf.range(0, ndata // 2 + 1, dtype=tf.float64) / (ndata // 2) / 2  # Frequency values 0 - 0.5\n",
    "    zerovalue = tf.cast(tf.constant([1.0]), dtype=tf.float64)\n",
    "    radius = tf.tensor_scatter_nd_update(radius, tf.constant([[0]]), zerovalue)\n",
    "    \n",
    "    wavelength = minWaveLength  # Initialize filter wavelength\n",
    "    \n",
    "    for s in range(nscale):\n",
    "        # Construct the filter - first calculate the radial filter component\n",
    "        fo = 1.0 / wavelength  # Centre frequency of filter\n",
    "        # corresponding to fo\n",
    "        \n",
    "        sum = tf.exp( tf.cast( - tf.pow((tf.math.log(radius/fo)), 2), dtype=tf.float32) / (2 * tf.pow(tf.math.log(sigmaOnf), 2)))\n",
    "\n",
    "\n",
    "        indexes = tf.expand_dims(tf.range(0, sum.shape[0]), axis=1)\n",
    "\n",
    "        logGabor = tf.tensor_scatter_nd_update(logGabor, indexes, sum)\n",
    "        logGabor = tf.tensor_scatter_nd_update(logGabor, tf.constant([[0]]), tf.constant([0.0]))\n",
    "        \n",
    "        filter = logGabor\n",
    "        filtersum = filtersum + filter\n",
    "        \n",
    "        for r in range(rows):\n",
    "            signal = im[r, 0:ndata]\n",
    "            imagefft = tf.signal.fft(tf.cast(signal, dtype=tf.complex128))\n",
    "            filter = tf.cast(filter, dtype=tf.complex128)\n",
    "            result = tf.tensor_scatter_nd_add(result, [tf.constant([r])], [tf.signal.ifft(imagefft * filter)])\n",
    "        \n",
    "        EO[s] = result\n",
    "        wavelength *= mult  # Finally calculate the wavelength of the next filter\n",
    "    \n",
    "    filtersum = tf.signal.fftshift(filtersum)\n",
    "    \n",
    "    return EO, filtersum\n",
    "\n",
    "def tf_encode(polar_array, nscales, minWaveLength, mult, sigmaOnf):\n",
    "    # Convoluzione della regione normalizzata con filtri di Gabor\n",
    "    E0, _ = tf_gaborconvolve(polar_array, nscales, minWaveLength, mult, sigmaOnf)\n",
    "    \n",
    "    H = tf.zeros(E0[0].shape)\n",
    "    for k in range(1, nscales + 1):\n",
    "        E1 = E0[k - 1]\n",
    "\n",
    "        cond_0 = tf.math.logical_and(tf.math.real(E1) <= 0, tf.math.imag(E1) <= 0)\n",
    "        cond_1 = tf.math.logical_and(tf.math.real(E1) <= 0, tf.math.imag(E1) > 0)\n",
    "        cond_2 = tf.math.logical_and(tf.math.real(E1) > 0, tf.math.imag(E1) <= 0)\n",
    "        cond_3 = tf.math.logical_and(tf.math.real(E1) > 0, tf.math.imag(E1) > 0)\n",
    "\n",
    "        H=tf.where(cond_0,0.0,H)\n",
    "        H=tf.where(cond_1,1.0,H)\n",
    "        H=tf.where(cond_2,2.0,H)\n",
    "        H=tf.where(cond_3,3.0,H)\n",
    "\n",
    "    return H\n",
    "\n",
    "def tf_GaborBitStreamSTACKED(AR): #polarImage):\n",
    "\n",
    "    #AR, AG, AB = tf.split(polarImage, num_or_size_splits=3, axis=-1)\n",
    "\n",
    "    nscales = 1\n",
    "    minWaveLength = 24\n",
    "    mult = 1\n",
    "    sigmaOnf = 0.5\n",
    "\n",
    "    TR = tf_encode(tf.squeeze(AR), nscales, minWaveLength, mult, sigmaOnf)\n",
    "    #TG = tf_encode(tf.squeeze(AG), nscales, minWaveLength, mult, sigmaOnf)\n",
    "    #TB = tf_encode(tf.squeeze(AB), nscales, minWaveLength, mult, sigmaOnf)\n",
    "\n",
    "    TR = tf.cast(TR, dtype=tf.uint8)\n",
    "\n",
    "    return tf.expand_dims(TR, axis=2) #return tf.concat([tf.expand_dims(TR, axis=2) , tf.expand_dims(TG, axis=2), tf.expand_dims(TB, axis=2)], axis=-1)\n",
    "\n",
    "def tf_daugman_feature_extractor(inp):\n",
    "    return tf_GaborBitStreamSTACKED(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485ddd73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:28.861161Z",
     "iopub.status.busy": "2023-10-16T09:42:28.860906Z",
     "iopub.status.idle": "2023-10-16T09:42:32.598354Z",
     "shell.execute_reply": "2023-10-16T09:42:32.597515Z"
    },
    "papermill": {
     "duration": 3.746028,
     "end_time": "2023-10-16T09:42:32.600314",
     "exception": false,
     "start_time": "2023-10-16T09:42:28.854286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# printing input image - feature image\n",
    "\n",
    "inp,tar = load(training_files[1])\n",
    "print(training_files[0])\n",
    "norm_inp = tf_daugman_normalization(inp)\n",
    "norm_tar = tf_daugman_normalization(tar)\n",
    "\n",
    "fi_inp= tf_daugman_feature_extractor(norm_inp)\n",
    "fi_tar = tf_daugman_feature_extractor(norm_tar)\n",
    "\n",
    "display_list = [inp/255.0 , norm_inp, fi_tar]\n",
    "title = ['Input Image', 'Norm_Input 1D', 'Feature Image']\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(display_list[i])\n",
    "    #plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3bdd9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:32.614881Z",
     "iopub.status.busy": "2023-10-16T09:42:32.614322Z",
     "iopub.status.idle": "2023-10-16T09:42:32.618962Z",
     "shell.execute_reply": "2023-10-16T09:42:32.618423Z"
    },
    "papermill": {
     "duration": 0.013364,
     "end_time": "2023-10-16T09:42:32.620421",
     "exception": false,
     "start_time": "2023-10-16T09:42:32.607057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image_train(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "\n",
    "    input_image = tf_daugman_normalization(input_image)\n",
    "\n",
    "    real_image = tf_daugman_normalization(real_image)\n",
    "    real_image = tf_daugman_feature_extractor(real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6c842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:32.654175Z",
     "iopub.status.busy": "2023-10-16T09:42:32.653595Z",
     "iopub.status.idle": "2023-10-16T09:42:32.657731Z",
     "shell.execute_reply": "2023-10-16T09:42:32.656968Z"
    },
    "papermill": {
     "duration": 0.012629,
     "end_time": "2023-10-16T09:42:32.659344",
     "exception": false,
     "start_time": "2023-10-16T09:42:32.646715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image_validation(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "\n",
    "    input_image = tf_daugman_normalization(input_image)\n",
    "\n",
    "    real_image = tf_daugman_normalization(real_image)\n",
    "    real_image = tf_daugman_feature_extractor(real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fd933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:32.673288Z",
     "iopub.status.busy": "2023-10-16T09:42:32.672701Z",
     "iopub.status.idle": "2023-10-16T09:42:32.676810Z",
     "shell.execute_reply": "2023-10-16T09:42:32.675879Z"
    },
    "papermill": {
     "duration": 0.012795,
     "end_time": "2023-10-16T09:42:32.678471",
     "exception": false,
     "start_time": "2023-10-16T09:42:32.665676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image_test(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "\n",
    "    input_image = tf_daugman_normalization(input_image)\n",
    "\n",
    "    real_image = tf_daugman_normalization(real_image)\n",
    "    real_image = tf_daugman_feature_extractor(real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b00297",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:32.731416Z",
     "iopub.status.busy": "2023-10-16T09:42:32.730895Z",
     "iopub.status.idle": "2023-10-16T09:42:33.220889Z",
     "shell.execute_reply": "2023-10-16T09:42:33.219990Z"
    },
    "papermill": {
     "duration": 0.49922,
     "end_time": "2023-10-16T09:42:33.223053",
     "exception": false,
     "start_time": "2023-10-16T09:42:32.723833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.list_files(str(DATASET_PATH / 'train/*.png'))\n",
    "train_dataset = train_dataset.map(load_image_train,\n",
    "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc45b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:33.237434Z",
     "iopub.status.busy": "2023-10-16T09:42:33.237182Z",
     "iopub.status.idle": "2023-10-16T09:42:33.295166Z",
     "shell.execute_reply": "2023-10-16T09:42:33.294343Z"
    },
    "papermill": {
     "duration": 0.067036,
     "end_time": "2023-10-16T09:42:33.296872",
     "exception": false,
     "start_time": "2023-10-16T09:42:33.229836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_dataset = tf.data.Dataset.from_tensor_slices(validation_files)\n",
    "validation_dataset = validation_dataset.map(load_image_validation)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ae206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:33.310657Z",
     "iopub.status.busy": "2023-10-16T09:42:33.310383Z",
     "iopub.status.idle": "2023-10-16T09:42:33.367296Z",
     "shell.execute_reply": "2023-10-16T09:42:33.366493Z"
    },
    "papermill": {
     "duration": 0.065838,
     "end_time": "2023-10-16T09:42:33.369122",
     "exception": false,
     "start_time": "2023-10-16T09:42:33.303284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_files)\n",
    "test_dataset = test_dataset.map(load_image_test,\n",
    "                                    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce6893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:38.095777Z",
     "iopub.status.busy": "2023-10-16T09:42:38.094880Z",
     "iopub.status.idle": "2023-10-16T09:42:38.100687Z",
     "shell.execute_reply": "2023-10-16T09:42:38.099763Z"
    },
    "papermill": {
     "duration": 0.014986,
     "end_time": "2023-10-16T09:42:38.102315",
     "exception": false,
     "start_time": "2023-10-16T09:42:38.087329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    \n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a87566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:38.135844Z",
     "iopub.status.busy": "2023-10-16T09:42:38.135360Z",
     "iopub.status.idle": "2023-10-16T09:42:38.140439Z",
     "shell.execute_reply": "2023-10-16T09:42:38.139625Z"
    },
    "papermill": {
     "duration": 0.013855,
     "end_time": "2023-10-16T09:42:38.142123",
     "exception": false,
     "start_time": "2023-10-16T09:42:38.128268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bdd46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:38.174849Z",
     "iopub.status.busy": "2023-10-16T09:42:38.174084Z",
     "iopub.status.idle": "2023-10-16T09:42:38.182210Z",
     "shell.execute_reply": "2023-10-16T09:42:38.181440Z"
    },
    "papermill": {
     "duration": 0.016848,
     "end_time": "2023-10-16T09:42:38.183878",
     "exception": false,
     "start_time": "2023-10-16T09:42:38.167030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS])\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False), \n",
    "        downsample(128, 4), \n",
    "        downsample(256, 4),  \n",
    "        downsample(512, 4),\n",
    "\n",
    "      ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True),  \n",
    "        upsample(256, 4), \n",
    "        upsample(128, 4),  \n",
    "        upsample(64, 4), \n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='softmax')  \n",
    "\n",
    "\n",
    "    # --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- #\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ff938",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:38.197911Z",
     "iopub.status.busy": "2023-10-16T09:42:38.197224Z",
     "iopub.status.idle": "2023-10-16T09:42:38.887932Z",
     "shell.execute_reply": "2023-10-16T09:42:38.886989Z"
    },
    "papermill": {
     "duration": 0.701193,
     "end_time": "2023-10-16T09:42:38.891415",
     "exception": false,
     "start_time": "2023-10-16T09:42:38.190222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "#tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e7e60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:38.910054Z",
     "iopub.status.busy": "2023-10-16T09:42:38.909778Z",
     "iopub.status.idle": "2023-10-16T09:42:45.610573Z",
     "shell.execute_reply": "2023-10-16T09:42:45.609723Z"
    },
    "papermill": {
     "duration": 6.712214,
     "end_time": "2023-10-16T09:42:45.612477",
     "exception": false,
     "start_time": "2023-10-16T09:42:38.900263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------- PRINT GENERATED IMAGES -------- #\n",
    "\n",
    "gen_output = generator(norm_inp[tf.newaxis, ...], training=False)\n",
    "#plt.imshow(gen_output[0, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285a26a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:45.632088Z",
     "iopub.status.busy": "2023-10-16T09:42:45.631823Z",
     "iopub.status.idle": "2023-10-16T09:42:46.366804Z",
     "shell.execute_reply": "2023-10-16T09:42:46.365971Z"
    },
    "papermill": {
     "duration": 0.75792,
     "end_time": "2023-10-16T09:42:46.379770",
     "exception": false,
     "start_time": "2023-10-16T09:42:45.621850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DiceLoss(y_true, y_pred, smooth=1e-6):\n",
    "    # convert the tensor to one-hot for multi-class segmentation\n",
    "    y_true = K.squeeze(y_true, 3)\n",
    "    y_true = tf.cast(y_true, \"int32\")\n",
    "    y_true = tf.one_hot(y_true, 4, axis=-1)\n",
    "    \n",
    "    # convert the tensor to one-hot for multi-class segmentation\n",
    "    #y_pred = K.squeeze(y_pred, 3)\n",
    "    #y_pred = tf.cast(y_pred, \"int32\")\n",
    "    #y_pred = tf.one_hot(y_pred, 4, axis=-1)\n",
    "    \n",
    "    # cast to float32 datatype\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    \n",
    "    #flatten label and prediction tensors\n",
    "    inputs = K.flatten(y_pred)\n",
    "    targets = K.flatten(y_true)\n",
    "\n",
    "    intersection = K.sum(targets * inputs)\n",
    "    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "    return 1 - dice\n",
    "\n",
    "\n",
    "#Tensorflow / Keras \n",
    "def IoULoss(y_true, y_pred, smooth=1e-6):\n",
    "    # convert the tensor to one-hot for multi-class segmentation\n",
    "    y_true = K.squeeze(y_true, 3)\n",
    "    y_true = tf.cast(y_true, \"int32\")\n",
    "    y_true = tf.one_hot(y_true, 4, axis=-1)\n",
    "\n",
    "    # convert the tensor to one-hot for multi-class segmentation\n",
    "    #y_pred = K.squeeze(y_pred, 3)\n",
    "    #y_pred = tf.cast(y_pred, \"int32\")\n",
    "    #y_pred = tf.one_hot(y_pred, 4, axis=-1)\n",
    "    \n",
    "    # cast to float32 datatype\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    \n",
    "    #flatten label and prediction tensors\n",
    "    inputs = K.flatten(y_pred)\n",
    "    targets = K.flatten(y_true)\n",
    "    \n",
    "    intersection = K.sum(targets * inputs)\n",
    "    total = K.sum(targets) + K.sum(inputs)\n",
    "    union = total - intersection\n",
    "    \n",
    "    IoU = (intersection + smooth) / (union + smooth)\n",
    "    return 1 - IoU\n",
    "\n",
    "scce_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    reduction='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07db03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:46.442421Z",
     "iopub.status.busy": "2023-10-16T09:42:46.442111Z",
     "iopub.status.idle": "2023-10-16T09:42:46.447158Z",
     "shell.execute_reply": "2023-10-16T09:42:46.446239Z"
    },
    "papermill": {
     "duration": 0.018793,
     "end_time": "2023-10-16T09:42:46.448866",
     "exception": false,
     "start_time": "2023-10-16T09:42:46.430073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    pw_loss = IoULoss(target, gen_output)\n",
    "    \n",
    "    total_gen_loss = gan_loss + (LAMBDA_P * pw_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, pw_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8709d27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:46.470918Z",
     "iopub.status.busy": "2023-10-16T09:42:46.470560Z",
     "iopub.status.idle": "2023-10-16T09:42:46.477197Z",
     "shell.execute_reply": "2023-10-16T09:42:46.476325Z"
    },
    "papermill": {
     "duration": 0.019677,
     "end_time": "2023-10-16T09:42:46.478860",
     "exception": false,
     "start_time": "2023-10-16T09:42:46.459183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, INPUT_CHANNELS], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar]) \n",
    "\n",
    "    down1 = downsample(64, 4, False)(x)  \n",
    "    down2 = downsample(128, 4)(down1) \n",
    "    down3 = downsample(256, 4)(down2) \n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1)  \n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) \n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2)  \n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7923f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:46.501249Z",
     "iopub.status.busy": "2023-10-16T09:42:46.500648Z",
     "iopub.status.idle": "2023-10-16T09:42:46.701380Z",
     "shell.execute_reply": "2023-10-16T09:42:46.700589Z"
    },
    "papermill": {
     "duration": 0.214549,
     "end_time": "2023-10-16T09:42:46.703774",
     "exception": false,
     "start_time": "2023-10-16T09:42:46.489225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b19fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:46.729529Z",
     "iopub.status.busy": "2023-10-16T09:42:46.728844Z",
     "iopub.status.idle": "2023-10-16T09:42:47.116508Z",
     "shell.execute_reply": "2023-10-16T09:42:47.115634Z"
    },
    "papermill": {
     "duration": 0.402284,
     "end_time": "2023-10-16T09:42:47.118301",
     "exception": false,
     "start_time": "2023-10-16T09:42:46.716017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------- PRINT DISCRIMINATOR OUTPUT  -------- #\n",
    "\n",
    "mask_prediction = create_mask(gen_output)\n",
    "\n",
    "disc_out = discriminator([fi_inp[tf.newaxis, ...], mask_prediction], training=False)\n",
    "plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b7b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:47.144277Z",
     "iopub.status.busy": "2023-10-16T09:42:47.144009Z",
     "iopub.status.idle": "2023-10-16T09:42:47.148263Z",
     "shell.execute_reply": "2023-10-16T09:42:47.147295Z"
    },
    "papermill": {
     "duration": 0.019219,
     "end_time": "2023-10-16T09:42:47.149940",
     "exception": false,
     "start_time": "2023-10-16T09:42:47.130721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae3df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:47.175359Z",
     "iopub.status.busy": "2023-10-16T09:42:47.174757Z",
     "iopub.status.idle": "2023-10-16T09:42:47.179985Z",
     "shell.execute_reply": "2023-10-16T09:42:47.179199Z"
    },
    "papermill": {
     "duration": 0.020079,
     "end_time": "2023-10-16T09:42:47.181669",
     "exception": false,
     "start_time": "2023-10-16T09:42:47.161590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation_step(generator, validation_ds) :\n",
    "    val_error = []\n",
    "    pw_error = []\n",
    "    gan_error = []\n",
    "    \n",
    "    for input_image, target in validation_ds:\n",
    "        gen_output = generator(input_image, training=False)\n",
    "    \n",
    "        fi_gen_output = create_mask(gen_output)\n",
    "        disc_generated_output = discriminator([input_image, fi_gen_output], training=False)\n",
    "\n",
    "        total_val_loss, ganloss, pw_loss =  generator_loss(disc_generated_output, gen_output, target)\n",
    "        val_error.append(total_val_loss)\n",
    "        gan_error.append(ganloss)\n",
    "        pw_error.append(pw_loss)\n",
    "\n",
    "    return np.mean(val_error), np.mean(gan_error), np.mean(pw_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e044e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:47.207401Z",
     "iopub.status.busy": "2023-10-16T09:42:47.207168Z",
     "iopub.status.idle": "2023-10-16T09:42:47.210777Z",
     "shell.execute_reply": "2023-10-16T09:42:47.209849Z"
    },
    "papermill": {
     "duration": 0.019086,
     "end_time": "2023-10-16T09:42:47.212421",
     "exception": false,
     "start_time": "2023-10-16T09:42:47.193335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_models(string, generator) :\n",
    "    generator.save('models/' + string)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33734587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:47.237883Z",
     "iopub.status.busy": "2023-10-16T09:42:47.237124Z",
     "iopub.status.idle": "2023-10-16T09:42:47.246366Z",
     "shell.execute_reply": "2023-10-16T09:42:47.245555Z"
    },
    "papermill": {
     "duration": 0.023895,
     "end_time": "2023-10-16T09:42:47.248012",
     "exception": false,
     "start_time": "2023-10-16T09:42:47.224117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_optimizer = tf.keras.optimizers.SGD()\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094ae44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:47.274533Z",
     "iopub.status.busy": "2023-10-16T09:42:47.273670Z",
     "iopub.status.idle": "2023-10-16T09:42:47.279596Z",
     "shell.execute_reply": "2023-10-16T09:42:47.278770Z"
    },
    "papermill": {
     "duration": 0.020536,
     "end_time": "2023-10-16T09:42:47.281249",
     "exception": false,
     "start_time": "2023-10-16T09:42:47.260713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "    prediction = model(test_input, training=False)\n",
    "    mask_prediction = create_mask(prediction)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    display_list = [test_input[0], tar[0], mask_prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # Getting the pixel values in the [0, 1] range to plot.\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be0ce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:47.306551Z",
     "iopub.status.busy": "2023-10-16T09:42:47.306273Z",
     "iopub.status.idle": "2023-10-16T09:42:47.311342Z",
     "shell.execute_reply": "2023-10-16T09:42:47.310454Z"
    },
    "papermill": {
     "duration": 0.019946,
     "end_time": "2023-10-16T09:42:47.312982",
     "exception": false,
     "start_time": "2023-10-16T09:42:47.293036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_images(model, test_input, tar, step):\n",
    "    prediction = model(test_input)#, training=True)\n",
    "    mask_prediction = create_mask(prediction)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    display_list = [test_input[0], tar[0], mask_prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # Getting the pixel values in the [0, 1] range to plot.\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "    #plt.show()\n",
    "    filename = 'image_' + str(step) + '.jpg'\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48566d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:47.369142Z",
     "iopub.status.busy": "2023-10-16T09:42:47.368881Z",
     "iopub.status.idle": "2023-10-16T09:42:47.378246Z",
     "shell.execute_reply": "2023-10-16T09:42:47.377354Z"
    },
    "papermill": {
     "duration": 0.024756,
     "end_time": "2023-10-16T09:42:47.379938",
     "exception": false,
     "start_time": "2023-10-16T09:42:47.355182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.create_file_writer(\n",
    "    LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5f302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:47.405757Z",
     "iopub.status.busy": "2023-10-16T09:42:47.405006Z",
     "iopub.status.idle": "2023-10-16T09:42:47.412684Z",
     "shell.execute_reply": "2023-10-16T09:42:47.411886Z"
    },
    "papermill": {
     "duration": 0.022523,
     "end_time": "2023-10-16T09:42:47.414545",
     "exception": false,
     "start_time": "2023-10-16T09:42:47.392022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target, step, gen_total_val_loss, gan_val_loss, pw_val_error):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        mask_prediction = create_mask(gen_output)\n",
    "        \n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, mask_prediction], training=True)\n",
    "\n",
    "        gen_total_loss, gan_loss, pw_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//trainingset_size)\n",
    "        tf.summary.scalar('gan_loss', gan_loss, step=step//trainingset_size)\n",
    "        tf.summary.scalar('pw_loss', pw_loss, step=step//trainingset_size)\n",
    "        tf.summary.scalar('disc_loss', disc_loss, step=step//trainingset_size)\n",
    "\n",
    "        tf.summary.scalar('gen_total_val_loss', gen_total_val_loss, step=step//trainingset_size)\n",
    "        tf.summary.scalar('gan_val_loss', gan_val_loss, step=step//trainingset_size)\n",
    "        tf.summary.scalar('pw_val_error', pw_val_error, step=step//trainingset_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6772cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:47.439987Z",
     "iopub.status.busy": "2023-10-16T09:42:47.439228Z",
     "iopub.status.idle": "2023-10-16T09:42:47.446754Z",
     "shell.execute_reply": "2023-10-16T09:42:47.445958Z"
    },
    "papermill": {
     "duration": 0.022141,
     "end_time": "2023-10-16T09:42:47.448415",
     "exception": false,
     "start_time": "2023-10-16T09:42:47.426274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(train_ds, validation_ds, test_ds, steps):\n",
    "    \n",
    "    example_input, example_target = next(iter(test_ds.take(1)))\n",
    "    start = time.time()\n",
    "    min_val_error = float(\"inf\")\n",
    "    gen_total_val_loss =  float(\"inf\")\n",
    "    pw_val_error =  float(\"inf\")\n",
    "    gan_val_loss =  float(\"inf\")\n",
    "    count = 0\n",
    "    count_stopping = 0\n",
    "\n",
    "    for step, (input_image, target) in train_ds.repeat().take(steps).enumerate():\n",
    "        \n",
    "        if (step) % trainingset_size == 0:\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "            if step != 0:\n",
    "                print(f'Time taken for an epoch: {time.time()-start:.2f} sec\\n')\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            generate_images(generator, example_input, example_target)\n",
    "            print(f\"Step: {step//trainingset_size}k\")\n",
    "\n",
    "        train_step(input_image, target, step, gen_total_val_loss, gan_val_loss, pw_val_error)\n",
    "\n",
    "        if ((count +1) % trainingset_size) == 0 :\n",
    "            gen_total_val_loss, gan_val_loss, pw_val_error = validation_step(generator, validation_ds)\n",
    "            print(\"gen_total_val_loss : \", gen_total_val_loss, \"   at step : \", count)\n",
    "            print(\"gen_val_loss : \", gan_val_loss, \"   at step : \", count)\n",
    "            print(\"pw_val_error : \", pw_val_error, \"   at step : \", count)\n",
    "            \n",
    "            if gen_total_val_loss < min_val_error :\n",
    "                print(\"updating min_val_error..\")\n",
    "                count_stopping = 0\n",
    "                min_val_error = gen_total_val_loss\n",
    "\n",
    "                filename = 'best_' + str(count + 1) + '.h5'\n",
    "                save_images(generator, example_input, example_target, count+1)\n",
    "                save_models(filename, generator)\n",
    "            else :\n",
    "                count_stopping = count_stopping +1 \n",
    "                \n",
    "        # Training step\n",
    "        if (step+1) % int(trainingset_size * 0.05) == 0:\n",
    "            print('.', end='', flush=True)\n",
    "                           \n",
    "        count = count +1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e0aa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T09:42:47.473831Z",
     "iopub.status.busy": "2023-10-16T09:42:47.473598Z",
     "iopub.status.idle": "2023-10-16T10:01:54.158464Z",
     "shell.execute_reply": "2023-10-16T10:01:54.157238Z"
    },
    "papermill": {
     "duration": 1146.700972,
     "end_time": "2023-10-16T10:01:54.161581",
     "exception": false,
     "start_time": "2023-10-16T09:42:47.460609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit(train_dataset, validation_dataset, test_dataset, steps= NSTEPS)\n",
    "save_models('last_model_.h5', generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1180.943205,
   "end_time": "2023-10-16T10:01:57.761035",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-16T09:42:16.817830",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
