{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T09:41:35.599618Z","iopub.status.busy":"2023-05-08T09:41:35.599182Z","iopub.status.idle":"2023-05-08T09:41:35.613564Z","shell.execute_reply":"2023-05-08T09:41:35.612112Z","shell.execute_reply.started":"2023-05-08T09:41:35.599588Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import save_img\n","from matplotlib import pyplot as plt\n","from os import mkdir, path\n","import tensorflow as tf\n","import numpy as np\n","import pathlib\n","import glob\n","import cv2\n","\n","\n","dataset = 'hk_dataset' # 'hk_dataset' or 'miche_dataset'\n","hk_validation = True\n","mirror = False \n","model_selection = True \n","\n","DATASET_PATH = 'task_1/dataset/processed_mirror_hk_dataset_320x256_ac_4/'\n","MODELS_PATH = 'task_1/transcoding/models/'\n","GENERATED_IMAGES_PATH = 'task_1/transcoding/results/hk_dataset/'\n","\n","# parameters for miche evaluation\n","right_eye_miche_subjects = [] # fill the array with subjects who has right eye acquisitions\n","\n","\n","models_list = [ 'best_pix2pix_bs4_vggloss3_L_100', \n","                'best_unet_bs4_l1_loss' ]\n","\n","\n","IMG_WIDTH = 320\n","IMG_HEIGHT = 256\n","LENGTH_IMAGE_NAME = 12 \n","\n","# real image size\n","hk_real_img_width = 640\n","hk_real_img_height = 480"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if dataset == 'hk_dataset' :\n","    f = 'test/*.png'\n","    LENGTH_IMAGE_NAME = 12 \n","\n","elif dataset == 'miche_dataset' :\n","    f = '/*.jpg'\n","    LENGTH_IMAGE_NAME = 24 \n","    \n","\n","if hk_validation : \n","    testset_files = glob.glob(DATASET_PATH + 'test/*.png')\n","    testset_files.sort()\n","\n","    new_test_files = []\n","    len_file = len(testset_files[1])\n","\n","    i=0\n","    for file in testset_files:\n","        sub = testset_files[i][len_file-11:len_file-8]\n","        if model_selection :\n","            if int(sub) <= 180 :\n","                new_test_files.append(file)\n","        else : \n","            if int(sub) > 180 :\n","                new_test_files.append(file)\n","        i = i+1 \n","        \n","    testset_files = new_test_files\n","    testset_size = len(testset_files)\n","\n","else :\n","    \n","    testset_files = glob.glob(DATASET_PATH + f)\n","    testset_files.sort()\n","    testset_size = len(testset_files)\n","\n","\n","PATHLIB_DATASET_PATH  = pathlib.Path(DATASET_PATH)\n","LENGTH_IMAGE_PATH = len(testset_files[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T09:41:35.617189Z","iopub.status.busy":"2023-05-08T09:41:35.616061Z","iopub.status.idle":"2023-05-08T09:41:35.623075Z","shell.execute_reply":"2023-05-08T09:41:35.622065Z","shell.execute_reply.started":"2023-05-08T09:41:35.617151Z"},"trusted":true},"outputs":[],"source":["def load(image_file):\n","    # Read and decode an image file to a uint8 tensor\n","    image = tf.io.read_file(image_file)\n","    #image = tfio.experimental.image.decode_tiff(image)\n","    #r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n","    #image = tf.stack([r, g, b], axis=-1)\n","    \n","\n","    if dataset == 'hk_dataset' : \n","        image = tf.io.decode_png(image)\n","\n","        # Split each image tensor into two tensors:\n","        # - one with a real building facade image\n","        # - one with an architecture label image \n","        w = tf.shape(image)[1]\n","        w = w // 2\n","\n","        input_image = image[:, :w, :]\n","        real_image = image[:, w:, :]\n","\n","        # Convert both images to float32 tensors\n","        input_image = tf.cast(input_image, tf.float32)\n","        real_image = tf.cast(real_image, tf.float32)\n","\n","    elif dataset == 'new_miche_dataset' :\n","        image = tf.io.decode_png(image)\n","\n","        input_image = image\n","        real_image = []\n","        \n","        # Convert both images to float32 tensors\n","        input_image = tf.cast(input_image, tf.float32)          \n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T09:41:35.625742Z","iopub.status.busy":"2023-05-08T09:41:35.624799Z","iopub.status.idle":"2023-05-08T09:41:35.640980Z","shell.execute_reply":"2023-05-08T09:41:35.639654Z","shell.execute_reply.started":"2023-05-08T09:41:35.625706Z"},"trusted":true},"outputs":[],"source":["def resize(input_image, real_image, height, width):\n","    input_image = tf.image.resize(input_image, [height, width],\n","                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    \n","    if dataset == 'hk_dataset' :\n","        real_image = tf.image.resize(real_image, [height, width],\n","                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","    \n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T09:41:35.644089Z","iopub.status.busy":"2023-05-08T09:41:35.643563Z","iopub.status.idle":"2023-05-08T09:41:35.653190Z","shell.execute_reply":"2023-05-08T09:41:35.652306Z","shell.execute_reply.started":"2023-05-08T09:41:35.644055Z"},"trusted":true},"outputs":[],"source":["# Normalizing the images to [-1, 1]\n","def normalize(input_image, real_image):\n","    input_image = (input_image / 127.5) - 1\n","    \n","    if dataset == 'hk_dataset' :\n","        real_image = (real_image / 127.5) - 1\n","         \n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T09:41:35.655031Z","iopub.status.busy":"2023-05-08T09:41:35.654382Z","iopub.status.idle":"2023-05-08T09:41:35.665492Z","shell.execute_reply":"2023-05-08T09:41:35.664187Z","shell.execute_reply.started":"2023-05-08T09:41:35.655000Z"},"trusted":true},"outputs":[],"source":["def generate_images(model, inp, tar):\n","    prediction = model(inp, training=False)\n","    plt.figure(figsize=(15, 15))\n","\n","    display_list = [tar[0], prediction[0]]\n","    title = ['Ground Truth', 'Predicted Image']\n","\n","    for i in range(2):\n","        plt.subplot(1, 2, i+1)\n","        plt.title(title[i])\n","        \n","        # Getting the pixel values in the [0, 1] range to plot.\n","        plt.imshow(display_list[i] * 0.5 + 0.5)\n","        plt.axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def print_images(gen_output, inp):\n","\n","    plt.figure(figsize=(15, 15))\n","    display_list = [inp[0], gen_output[0]]\n","    title = ['Ground Truth', 'Predicted Image']\n","    \n","    for i in range(2):\n","        plt.subplot(1, 2, i+1)\n","        plt.title(title[i])\n","\n","        # Getting the pixel values in the [0, 1] range to plot.\n","        plt.imshow(display_list[i] * 0.5 + 0.5)\n","        plt.axis('off')\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def save_image(image, images_path, i):\n","    file_name = testset_files[i][LENGTH_IMAGE_PATH-LENGTH_IMAGE_NAME:LENGTH_IMAGE_PATH]  \n","    file_path = images_path + '/' + file_name \n","\n","    img = image[0].numpy()\n","    \n","    if dataset == 'hk_dataset' and not mirror and file_name[5] == 'R':\n","        img = img[:, ::-1, :]\n","\n","    img = cv2.normalize(img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n","    img = img.astype(np.uint8)\n","\n","    if dataset == 'miche_dataset' :\n","        real_img_path = DATASET_PATH + file_name\n","        real_img = cv2.imread(real_img_path)\n","        real_img_height = real_img.shape[0]\n","        real_img_width = real_img.shape[1]\n","\n","        subj = int(file_name[0:3])\n","        if (subj in right_eye_miche_subjects) and not mirror : \n","            img = img[:, ::-1, :]\n","\n","        img = cv2.resize(img, (real_img_width,real_img_height))\n","    \n","    elif dataset == 'hk_dataset' :\n","        img = cv2.resize(img, (hk_real_img_width ,hk_real_img_height))\n","   \n","    cv2.imwrite(file_path, img, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# printing img testset \n","\n","inp, re = load(testset_files[1])\n","inp, re = resize(inp,re, IMG_HEIGHT, IMG_WIDTH)\n","inp, re = normalize(inp,re)\n","plt.figure(figsize=(6, 6))\n","\n","display_list = [inp]\n","title = ['Ground Truth']\n","\n","for i in range(1):\n","    plt.subplot(1, 2, i+1)\n","    plt.title(title[i])\n","    plt.imshow(display_list[i]* 0.5 + 0.5)\n","    plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T09:41:35.667763Z","iopub.status.busy":"2023-05-08T09:41:35.667426Z","iopub.status.idle":"2023-05-08T09:41:35.678595Z","shell.execute_reply":"2023-05-08T09:41:35.677384Z","shell.execute_reply.started":"2023-05-08T09:41:35.667733Z"},"trusted":true},"outputs":[],"source":["def load_image_test(image_file):\n","    \n","    input_image, real_image = load(image_file)\n","    input_image, real_image = normalize(input_image, real_image)\n","\n","    if not dataset == 'hk_dataset' :\n","        input_image, real_image = resize(input_image, real_image, IMG_HEIGHT, IMG_WIDTH)\n","\n","    return input_image, real_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T09:41:35.680557Z","iopub.status.busy":"2023-05-08T09:41:35.679799Z","iopub.status.idle":"2023-05-08T09:41:35.948344Z","shell.execute_reply":"2023-05-08T09:41:35.947016Z","shell.execute_reply.started":"2023-05-08T09:41:35.680526Z"},"trusted":true},"outputs":[],"source":["if dataset == 'hk_dataset' :\n","    f = 'test/*.png'\n","    \n","elif dataset == 'miche_dataset':\n","    f = '*.jpg'\n","\n","if hk_validation :\n","    test_dataset = tf.data.Dataset.from_tensor_slices(testset_files)\n","    test_dataset = test_dataset.map(load_image_test)\n","    test_dataset = test_dataset.batch(1)\n","else :\n","    test_dataset = tf.data.Dataset.list_files(str(PATHLIB_DATASET_PATH / f), shuffle=False)\n","    test_dataset = test_dataset.map(load_image_test)\n","    test_dataset = test_dataset.batch(1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generator_loss(target, gen_output):\n","    # PSNR \n","    psnr_loss = tf.image.psnr(target, gen_output, max_val=2.0) # images shuld have been normalized in range [-1,1]. Thus, the difference between the min and max should be 2.\n","    \n","    # SSIM \n","    ssim_loss = tf.image.ssim(target, gen_output, max_val=2.0)\n","\n","    # Mean absolute error\n","    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n","\n","    # Mean squared error\n","    l2_loss = tf.reduce_mean(tf.abs(target - gen_output)**2)\n","    \n","    return psnr_loss.numpy().item(0), ssim_loss.numpy().item(0), l1_loss.numpy(), l2_loss.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T09:41:40.733975Z","iopub.status.busy":"2023-05-08T09:41:40.733521Z","iopub.status.idle":"2023-05-08T09:43:42.460664Z","shell.execute_reply":"2023-05-08T09:43:42.459393Z","shell.execute_reply.started":"2023-05-08T09:41:40.733935Z"},"trusted":true},"outputs":[],"source":["for model_name in models_list :\n","    \n","    generator = tf.keras.models.load_model(MODELS_PATH + model_name + '.h5', compile=False)\n","    model_images_path = GENERATED_IMAGES_PATH + model_name\n","\n","    mkdir(model_images_path)\n","\n","    sum_l1_losses = [] \n","    sum_l2_losses = []\n","    sum_psnr_losses = []\n","    sum_ssim_losses = []\n","\n","    n_image = 0\n","    for inp, tar in test_dataset :\n","        gen_output = generator(inp, training=False)\n","\n","        #print_images(gen_output, inp)\n","\n","        if dataset == 'hk_dataset' : \n","            psnr_loss, ssim_loss, l1_loss, l2_loss = generator_loss(tar, gen_output)\n","\n","            sum_psnr_losses.append(psnr_loss)\n","            sum_ssim_losses.append(ssim_loss)\n","            sum_l1_losses.append(l1_loss)\n","            sum_l2_losses.append(l2_loss)\n","        \n","        save_image(gen_output, model_images_path, n_image)\n","        n_image = n_image + 1\n","\n","    if dataset == 'hk_dataset' : \n","        print('\\t' + model_name)\n","        print(\"\\t  PSNR loss\")\n","        print(\"\\t\\t  mean  : \" +  \"{:.2f}\".format(np.mean(sum_psnr_losses)) +  \"\\tvar : \" +  \"{:.2f}\".format(np.var(sum_psnr_losses)))\n","        print(\"\\t  SSIM loss\")\n","        print(\"\\t\\t  mean  : \" +  \"{:.2f}\".format(np.mean(sum_ssim_losses)) +  \"\\tvar : \" +  \"{:.2f}\".format(np.var(sum_ssim_losses)))\n","        print(\"\\t  L1 loss - L2 loss\")\n","        print(\"\\t\\t  l1_loss  : \" +  \"{:.2f}\".format(np.mean(sum_l1_losses)) +  \"\\tl2_loss : \" +  \"{:.2f}\".format(np.var(sum_l1_losses)))\n","        print(\"\\t\\t  l2_loss  : \" +  \"{:.2f}\".format(np.mean(sum_l2_losses)) +  \"\\tl2_loss : \" +  \"{:.2f}\".format(np.var(sum_l2_losses)))\n","\n","        print(\"\\n\\n\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
